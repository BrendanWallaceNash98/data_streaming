:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-252aefe4-f09a-4a2b-b6ec-1709e61bc5b1;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 in central
	found org.apache.kafka#kafka-clients;2.6.0 in central
	found com.github.luben#zstd-jni;1.4.8-1 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.2 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
	found com.datastax.spark#spark-cassandra-connector_2.12;3.1.0 in central
	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 in central
	found com.datastax.oss#java-driver-core-shaded;4.12.0 in central
	found com.datastax.oss#native-protocol;1.5.0 in central
	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
	found com.typesafe#config;1.4.1 in central
	found io.dropwizard.metrics#metrics-core;4.1.18 in central
	found org.hdrhistogram#HdrHistogram;2.1.12 in central
	found org.reactivestreams#reactive-streams;1.0.3 in central
	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
	found com.google.code.findbugs#jsr305;3.0.2 in central
	found com.datastax.oss#java-driver-mapper-runtime;4.12.0 in central
	found com.datastax.oss#java-driver-query-builder;4.12.0 in central
	found org.apache.commons#commons-lang3;3.10 in central
	found com.thoughtworks.paranamer#paranamer;2.8 in central
	found org.scala-lang#scala-reflect;2.12.11 in central
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.1/spark-sql-kafka-0-10_2.12-3.1.1.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1!spark-sql-kafka-0-10_2.12.jar (601ms)
downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.1.0/spark-cassandra-connector_2.12-3.1.0.jar ...
	[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector_2.12;3.1.0!spark-cassandra-connector_2.12.jar (1144ms)
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.1.1/spark-token-provider-kafka-0-10_2.12-3.1.1.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1!spark-token-provider-kafka-0-10_2.12.jar (366ms)
downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.6.0/kafka-clients-2.6.0.jar ...
	[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.6.0!kafka-clients.jar (1731ms)
downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar ...
	[SUCCESSFUL ] org.apache.commons#commons-pool2;2.6.2!commons-pool2.jar (776ms)
downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...
	[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (443ms)
downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.8-1/zstd-jni-1.4.8-1.jar ...
	[SUCCESSFUL ] com.github.luben#zstd-jni;1.4.8-1!zstd-jni.jar (7549ms)
downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar ...
	[SUCCESSFUL ] org.lz4#lz4-java;1.7.1!lz4-java.jar (1012ms)
downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar ...
	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.2!snappy-java.jar(bundle) (2449ms)
downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar ...
	[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.30!slf4j-api.jar (358ms)
downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.1.0/spark-cassandra-connector-driver_2.12-3.1.0.jar ...
	[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0!spark-cassandra-connector-driver_2.12.jar (1290ms)
downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.12.0/java-driver-core-shaded-4.12.0.jar ...
	[SUCCESSFUL ] com.datastax.oss#java-driver-core-shaded;4.12.0!java-driver-core-shaded.jar (4472ms)
downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.12.0/java-driver-mapper-runtime-4.12.0.jar ...
	[SUCCESSFUL ] com.datastax.oss#java-driver-mapper-runtime;4.12.0!java-driver-mapper-runtime.jar(bundle) (348ms)
downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar ...
	[SUCCESSFUL ] org.apache.commons#commons-lang3;3.10!commons-lang3.jar (474ms)
downloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar ...
	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.8!paranamer.jar(bundle) (443ms)
downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.11/scala-reflect-2.12.11.jar ...
	[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.11!scala-reflect.jar (1598ms)
downloading https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar ...
	[SUCCESSFUL ] com.datastax.oss#native-protocol;1.5.0!native-protocol.jar(bundle) (409ms)
downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar ...
	[SUCCESSFUL ] com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1!java-driver-shaded-guava.jar (981ms)
downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar ...
	[SUCCESSFUL ] com.typesafe#config;1.4.1!config.jar(bundle) (456ms)
downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar ...
	[SUCCESSFUL ] io.dropwizard.metrics#metrics-core;4.1.18!metrics-core.jar(bundle) (349ms)
downloading https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar ...
	[SUCCESSFUL ] org.hdrhistogram#HdrHistogram;2.1.12!HdrHistogram.jar(bundle) (374ms)
downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...
	[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (334ms)
downloading https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar ...
	[SUCCESSFUL ] com.github.stephenc.jcip#jcip-annotations;1.0-1!jcip-annotations.jar (334ms)
downloading https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar ...
	[SUCCESSFUL ] com.github.spotbugs#spotbugs-annotations;3.1.12!spotbugs-annotations.jar (353ms)
downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...
	[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (350ms)
downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.12.0/java-driver-query-builder-4.12.0.jar ...
	[SUCCESSFUL ] com.datastax.oss#java-driver-query-builder;4.12.0!java-driver-query-builder.jar(bundle) (379ms)
:: resolution report :: resolve 27960ms :: artifacts dl 29387ms
	:: modules in use:
	com.datastax.oss#java-driver-core-shaded;4.12.0 from central in [default]
	com.datastax.oss#java-driver-mapper-runtime;4.12.0 from central in [default]
	com.datastax.oss#java-driver-query-builder;4.12.0 from central in [default]
	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
	com.datastax.oss#native-protocol;1.5.0 from central in [default]
	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 from central in [default]
	com.datastax.spark#spark-cassandra-connector_2.12;3.1.0 from central in [default]
	com.github.luben#zstd-jni;1.4.8-1 from central in [default]
	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
	com.typesafe#config;1.4.1 from central in [default]
	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
	org.apache.commons#commons-lang3;3.10 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.6.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.1 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.1 from central in [default]
	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
	org.scala-lang#scala-reflect;2.12.11 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
	:: evicted modules:
	org.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;1.7.30] in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   27  |   26  |   26  |   1   ||   26  |   26  |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-252aefe4-f09a-4a2b-b6ec-1709e61bc5b1
	confs: [default]
	26 artifacts copied, 0 already retrieved (31091kB/33ms)
24/09/13 02:42:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-09-13 02:42:03,900 - INFO - Starting Spark Streaming application
2024-09-13 02:42:03,900 - INFO - Attempting to create Spark connection
24/09/13 02:42:03 INFO SparkContext: Running Spark version 3.5.2
24/09/13 02:42:03 INFO SparkContext: OS info Linux, 6.6.26-linuxkit, aarch64
24/09/13 02:42:03 INFO SparkContext: Java version 17.0.12
24/09/13 02:42:03 INFO ResourceUtils: ==============================================================
24/09/13 02:42:03 INFO ResourceUtils: No custom resources configured for spark.driver.
24/09/13 02:42:03 INFO ResourceUtils: ==============================================================
24/09/13 02:42:03 INFO SparkContext: Submitted application: SparkDataStreaming
24/09/13 02:42:03 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/09/13 02:42:03 INFO ResourceProfile: Limiting resource is cpu
24/09/13 02:42:03 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/09/13 02:42:03 INFO SecurityManager: Changing view acls to: spark
24/09/13 02:42:03 INFO SecurityManager: Changing modify acls to: spark
24/09/13 02:42:03 INFO SecurityManager: Changing view acls groups to: 
24/09/13 02:42:03 INFO SecurityManager: Changing modify acls groups to: 
24/09/13 02:42:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
24/09/13 02:42:04 INFO Utils: Successfully started service 'sparkDriver' on port 33377.
24/09/13 02:42:04 INFO SparkEnv: Registering MapOutputTracker
24/09/13 02:42:04 INFO SparkEnv: Registering BlockManagerMaster
24/09/13 02:42:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/09/13 02:42:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/09/13 02:42:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/09/13 02:42:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-63da41f8-a197-40c2-9d0c-7c87ad13c8aa
24/09/13 02:42:04 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
24/09/13 02:42:04 INFO SparkEnv: Registering OutputCommitCoordinator
24/09/13 02:42:04 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/09/13 02:42:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at spark://325496eabbd9:33377/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.1.0.jar at spark://325496eabbd9:33377/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.1.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at spark://325496eabbd9:33377/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at spark://325496eabbd9:33377/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://325496eabbd9:33377/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://325496eabbd9:33377/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at spark://325496eabbd9:33377/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://325496eabbd9:33377/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at spark://325496eabbd9:33377/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://325496eabbd9:33377/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.1.0.jar at spark://325496eabbd9:33377/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.1.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.12.0.jar at spark://325496eabbd9:33377/jars/com.datastax.oss_java-driver-core-shaded-4.12.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.12.0.jar at spark://325496eabbd9:33377/jars/com.datastax.oss_java-driver-mapper-runtime-4.12.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://325496eabbd9:33377/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://325496eabbd9:33377/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://325496eabbd9:33377/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://325496eabbd9:33377/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://325496eabbd9:33377/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://325496eabbd9:33377/jars/com.typesafe_config-1.4.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://325496eabbd9:33377/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://325496eabbd9:33377/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://325496eabbd9:33377/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://325496eabbd9:33377/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://325496eabbd9:33377/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://325496eabbd9:33377/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.12.0.jar at spark://325496eabbd9:33377/jars/com.datastax.oss_java-driver-query-builder-4.12.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar at spark://325496eabbd9:33377/files/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.1.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.1.0.jar at spark://325496eabbd9:33377/files/com.datastax.spark_spark-cassandra-connector_2.12-3.1.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.1.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.datastax.spark_spark-cassandra-connector_2.12-3.1.0.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar at spark://325496eabbd9:33377/files/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.1.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at spark://325496eabbd9:33377/files/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.apache.kafka_kafka-clients-2.6.0.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://325496eabbd9:33377/files/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.apache.commons_commons-pool2-2.6.2.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://325496eabbd9:33377/files/org.spark-project.spark_unused-1.0.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.spark-project.spark_unused-1.0.0.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at spark://325496eabbd9:33377/files/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.github.luben_zstd-jni-1.4.8-1.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://325496eabbd9:33377/files/org.lz4_lz4-java-1.7.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.lz4_lz4-java-1.7.1.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at spark://325496eabbd9:33377/files/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.xerial.snappy_snappy-java-1.1.8.2.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://325496eabbd9:33377/files/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.slf4j_slf4j-api-1.7.30.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.1.0.jar at spark://325496eabbd9:33377/files/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.1.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.1.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.1.0.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.12.0.jar at spark://325496eabbd9:33377/files/com.datastax.oss_java-driver-core-shaded-4.12.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.12.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.datastax.oss_java-driver-core-shaded-4.12.0.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.12.0.jar at spark://325496eabbd9:33377/files/com.datastax.oss_java-driver-mapper-runtime-4.12.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.12.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.datastax.oss_java-driver-mapper-runtime-4.12.0.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://325496eabbd9:33377/files/org.apache.commons_commons-lang3-3.10.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.apache.commons_commons-lang3-3.10.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://325496eabbd9:33377/files/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.thoughtworks.paranamer_paranamer-2.8.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://325496eabbd9:33377/files/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.scala-lang_scala-reflect-2.12.11.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://325496eabbd9:33377/files/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.datastax.oss_native-protocol-1.5.0.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://325496eabbd9:33377/files/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://325496eabbd9:33377/files/com.typesafe_config-1.4.1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.typesafe_config-1.4.1.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://325496eabbd9:33377/files/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/io.dropwizard.metrics_metrics-core-4.1.18.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://325496eabbd9:33377/files/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.hdrhistogram_HdrHistogram-2.1.12.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://325496eabbd9:33377/files/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/org.reactivestreams_reactive-streams-1.0.3.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://325496eabbd9:33377/files/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://325496eabbd9:33377/files/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://325496eabbd9:33377/files/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.google.code.findbugs_jsr305-3.0.2.jar
24/09/13 02:42:04 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.12.0.jar at spark://325496eabbd9:33377/files/com.datastax.oss_java-driver-query-builder-4.12.0.jar with timestamp 1726195323937
24/09/13 02:42:04 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.12.0.jar to /tmp/spark-9c17b35c-6b4e-443d-a26a-8e65d19c050e/userFiles-bcacad5e-6b9d-41ee-8754-e1444493c3f0/com.datastax.oss_java-driver-query-builder-4.12.0.jar
24/09/13 02:42:04 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
24/09/13 02:42:04 INFO TransportClientFactory: Successfully created connection to spark-master/172.24.0.3:7077 after 14 ms (0 ms spent in bootstraps)
24/09/13 02:42:04 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20240913024204-0000
24/09/13 02:42:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34679.
24/09/13 02:42:04 INFO NettyBlockTransferService: Server created on 325496eabbd9:34679
24/09/13 02:42:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/13 02:42:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 325496eabbd9, 34679, None)
24/09/13 02:42:04 INFO BlockManagerMasterEndpoint: Registering block manager 325496eabbd9:34679 with 434.4 MiB RAM, BlockManagerId(driver, 325496eabbd9, 34679, None)
24/09/13 02:42:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 325496eabbd9, 34679, None)
24/09/13 02:42:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 325496eabbd9, 34679, None)
24/09/13 02:42:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20240913024204-0000/0 on worker-20240913024055-172.24.0.8-44817 (172.24.0.8:44817) with 2 core(s)
24/09/13 02:42:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20240913024204-0000/0 on hostPort 172.24.0.8:44817 with 2 core(s), 1024.0 MiB RAM
24/09/13 02:42:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20240913024204-0000/0 is now RUNNING
24/09/13 02:42:04 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2024-09-13 02:42:04,909 - INFO - Spark connection created successfully
24/09/13 02:42:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
24/09/13 02:42:04 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2024-09-13 02:42:05,650 - INFO - Successfully connected to Kafka
root
 |-- key: binary (nullable = true)
 |-- value: binary (nullable = true)
 |-- topic: string (nullable = true)
 |-- partition: integer (nullable = true)
 |-- offset: long (nullable = true)
 |-- timestamp: timestamp (nullable = true)
 |-- timestampType: integer (nullable = true)

2024-09-13 02:42:05,663 - INFO - Kafka schema: None
2024-09-13 02:42:05,832 - INFO - Created DataFrame from Kafka stream
2024-09-13 02:42:05,877 - WARNING - Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['cassandra_db'], lbp = None)
2024-09-13 02:42:05,890 - INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '172.24.0.2:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
2024-09-13 02:42:05,916 - INFO - Successfully connected to Cassandra
2024-09-13 02:42:05,917 - INFO - Keyspace created successfully
2024-09-13 02:42:05,919 - INFO - Table created successfully!
2024-09-13 02:42:05,935 - INFO - Callback Server Starting
2024-09-13 02:42:05,935 - INFO - Socket listening on ('127.0.0.1', 43361)
24/09/13 02:42:05 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
24/09/13 02:42:05 INFO ResolveWriteToStream: Checkpoint root /tmp/checkpoint resolved to file:/tmp/checkpoint.
24/09/13 02:42:05 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
24/09/13 02:42:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/metadata using temp file file:/tmp/checkpoint/.metadata.bfc45113-b60e-4bb0-ad2d-9fbf1d350cb3.tmp
24/09/13 02:42:06 INFO StandaloneSchedulerBackend$StandaloneDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.24.0.8:37246) with ID 0,  ResourceProfileId 0
24/09/13 02:42:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/.metadata.bfc45113-b60e-4bb0-ad2d-9fbf1d350cb3.tmp to file:/tmp/checkpoint/metadata
24/09/13 02:42:06 INFO BlockManagerMasterEndpoint: Registering block manager 172.24.0.8:42021 with 434.4 MiB RAM, BlockManagerId(0, 172.24.0.8, 42021, None)
24/09/13 02:42:06 INFO MicroBatchExecution: Starting [id = b7ac8922-8d26-430a-83ec-671d095ee3df, runId = ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4]. Use file:/tmp/checkpoint to store the query checkpoint.
2024-09-13 02:42:06,136 - INFO - Streaming query started
24/09/13 02:42:06 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@4c1d4015] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@4c00c018]
24/09/13 02:42:06 INFO OffsetSeqLog: BatchIds found from listing: 
24/09/13 02:42:06 INFO OffsetSeqLog: BatchIds found from listing: 
24/09/13 02:42:06 INFO MicroBatchExecution: Starting new streaming query.
24/09/13 02:42:06 INFO MicroBatchExecution: Stream started from {}
24/09/13 02:42:06 INFO AdminClientConfig: AdminClientConfig values: 
	bootstrap.servers = [broker:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

24/09/13 02:42:06 WARN AdminClientConfig: The configuration 'key.deserializer' was supplied but isn't a known config.
24/09/13 02:42:06 WARN AdminClientConfig: The configuration 'value.deserializer' was supplied but isn't a known config.
24/09/13 02:42:06 WARN AdminClientConfig: The configuration 'enable.auto.commit' was supplied but isn't a known config.
24/09/13 02:42:06 WARN AdminClientConfig: The configuration 'max.poll.records' was supplied but isn't a known config.
24/09/13 02:42:06 WARN AdminClientConfig: The configuration 'auto.offset.reset' was supplied but isn't a known config.
24/09/13 02:42:06 INFO AppInfoParser: Kafka version: 2.6.0
24/09/13 02:42:06 INFO AppInfoParser: Kafka commitId: 62abe01bee039651
24/09/13 02:42:06 INFO AppInfoParser: Kafka startTimeMs: 1726195326411
24/09/13 02:42:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/sources/0/0 using temp file file:/tmp/checkpoint/sources/0/.0.84efd692-9f2e-4b1e-ae28-3e601c45aa53.tmp
24/09/13 02:42:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/sources/0/.0.84efd692-9f2e-4b1e-ae28-3e601c45aa53.tmp to file:/tmp/checkpoint/sources/0/0
24/09/13 02:42:06 INFO KafkaMicroBatchStream: Initial offsets: {"user_data":{"0":0}}
24/09/13 02:42:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/0 using temp file file:/tmp/checkpoint/offsets/.0.157a3c3e-d24a-454b-9acc-33ae5a4faace.tmp
24/09/13 02:42:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.0.157a3c3e-d24a-454b-9acc-33ae5a4faace.tmp to file:/tmp/checkpoint/offsets/0
24/09/13 02:42:06 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1726195326653,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:42:06 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:42:06 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:42:06 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:42:06 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:42:07 INFO CodeGenerator: Code generated in 89.5555 ms
2024-09-13 02:42:07,166 - INFO - Python Server ready to receive messages
2024-09-13 02:42:07,166 - INFO - Received command c on object id p0
24/09/13 02:42:07 INFO CodeGenerator: Code generated in 4.045875 ms
2024-09-13 02:42:07,191 - INFO - Batch 0 is empty
2024-09-13 02:42:07,191 - INFO - Finished processing batch 0
24/09/13 02:42:07 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/0 using temp file file:/tmp/checkpoint/commits/.0.18ab7c82-6012-4bb5-ad4c-13585fb3ecfa.tmp
24/09/13 02:42:07 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.0.18ab7c82-6012-4bb5-ad4c-13585fb3ecfa.tmp to file:/tmp/checkpoint/commits/0
24/09/13 02:42:07 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:42:06.152Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "addBatch" : 270,
    "commitOffsets" : 17,
    "getBatch" : 13,
    "latestOffset" : 489,
    "queryPlanning" : 230,
    "triggerExecution" : 1057,
    "walCommit" : 18
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : null,
    "endOffset" : {
      "user_data" : {
        "0" : 0
      }
    },
    "latestOffset" : null,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:42:20 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
24/09/13 02:42:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
24/09/13 02:42:45 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/1 using temp file file:/tmp/checkpoint/offsets/.1.f56772cf-1c80-46ec-b078-b367c1576a2f.tmp
24/09/13 02:42:45 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.1.f56772cf-1c80-46ec-b078-b367c1576a2f.tmp to file:/tmp/checkpoint/offsets/1
24/09/13 02:42:45 INFO MicroBatchExecution: Committed offsets for batch 1. Metadata OffsetSeqMetadata(0,1726195365011,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:42:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:42:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:42:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:42:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:42:45,097 - INFO - Received command c on object id p0
24/09/13 02:42:45 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
24/09/13 02:42:45 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:42:45 INFO DAGScheduler: Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)
24/09/13 02:42:45 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:42:45 INFO DAGScheduler: Missing parents: List()
24/09/13 02:42:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:42:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 42.8 KiB, free 434.4 MiB)
24/09/13 02:42:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.3 MiB)
24/09/13 02:42:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:42:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
24/09/13 02:42:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:42:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
24/09/13 02:42:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:42:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:42:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1573 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:42:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/09/13 02:42:46 INFO DAGScheduler: ResultStage 0 (start at NativeMethodAccessorImpl.java:0) finished in 1.696 s
24/09/13 02:42:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:42:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/09/13 02:42:46 INFO DAGScheduler: Job 0 finished: start at NativeMethodAccessorImpl.java:0, took 1.719577 s
2024-09-13 02:42:46,845 - INFO - Processing batch 1
2024-09-13 02:42:46,845 - INFO - Batch content:
24/09/13 02:42:46 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:42:46 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:42:46 INFO CodeGenerator: Code generated in 23.06375 ms
24/09/13 02:42:46 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0
24/09/13 02:42:46 INFO DAGScheduler: Got job 1 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:42:46 INFO DAGScheduler: Final stage: ResultStage 1 (start at NativeMethodAccessorImpl.java:0)
24/09/13 02:42:46 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:42:46 INFO DAGScheduler: Missing parents: List()
24/09/13 02:42:46 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[15] at start at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:42:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 46.6 KiB, free 434.4 MiB)
24/09/13 02:42:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.3 MiB)
24/09/13 02:42:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:42:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
24/09/13 02:42:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[15] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:42:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
24/09/13 02:42:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:42:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:42:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 584 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:42:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/09/13 02:42:47 INFO DAGScheduler: ResultStage 1 (start at NativeMethodAccessorImpl.java:0) finished in 0.590 s
24/09/13 02:42:47 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:42:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/09/13 02:42:47 INFO DAGScheduler: Job 1 finished: start at NativeMethodAccessorImpl.java:0, took 0.593423 s
24/09/13 02:42:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:42:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:42:48 INFO CodeGenerator: Code generated in 15.215 ms
+----+----------+---------+------+------------+---------+----------------+--------+----------+---------------+----------+---------------------------+
|id  |first_name|last_name|gender|address     |post_code|email           |username|dob       |registered_date|phone     |picture                    |
+----+----------+---------+------+------------+---------+----------------+--------+----------+---------------+----------+---------------------------+
|NULL|Jane      |Smith    |female|456 Test Ave|67890    |jane@example.com|janes   |1995-05-05|2024-02-02     |9876543210|http://example.com/jane.jpg|
+----+----------+---------+------+------------+---------+----------------+--------+----------+---------------+----------+---------------------------+

24/09/13 02:42:48 INFO CodeGenerator: Code generated in 10.501125 ms
24/09/13 02:42:48 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:42:48 INFO DAGScheduler: Got job 2 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:42:48 INFO DAGScheduler: Final stage: ResultStage 2 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:42:48 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:42:48 INFO DAGScheduler: Missing parents: List()
24/09/13 02:42:48 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:42:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 45.7 KiB, free 434.4 MiB)
24/09/13 02:42:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:42:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:42:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
24/09/13 02:42:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:42:48 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
24/09/13 02:42:48 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:42:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:42:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 579 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:42:48 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/09/13 02:42:48 INFO DAGScheduler: ResultStage 2 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.596 s
24/09/13 02:42:48 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:42:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
24/09/13 02:42:48 INFO DAGScheduler: Job 2 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.599838 s
2024-09-13 02:42:48,770 - INFO - Inserting data: {'id': None, 'first_name': 'Jane', 'last_name': 'Smith', 'gender': 'female', 'address': '456 Test Ave', 'post_code': '67890', 'email': 'jane@example.com', 'username': 'janes', 'dob': '1995-05-05', 'registered_date': '2024-02-02', 'phone': '9876543210', 'picture': 'http://example.com/jane.jpg'}
2024-09-13 02:42:48,776 - INFO - Data inserted for Jane Smith with ID cdc731c1-d31a-41ad-97cb-3bd4e0cf3ab5
2024-09-13 02:42:48,776 - INFO - Successfully inserted data for Jane Smith
2024-09-13 02:42:48,776 - INFO - Finished processing batch 1
24/09/13 02:42:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/1 using temp file file:/tmp/checkpoint/commits/.1.45bf5046-be8c-492d-b09a-ebe66cb4bb80.tmp
24/09/13 02:42:48 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.1.45bf5046-be8c-492d-b09a-ebe66cb4bb80.tmp to file:/tmp/checkpoint/commits/1
24/09/13 02:42:48 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:42:45.002Z",
  "batchId" : 1,
  "numInputRows" : 3,
  "inputRowsPerSecond" : 0.6,
  "processedRowsPerSecond" : 0.790722192936215,
  "durationMs" : {
    "addBatch" : 3708,
    "commitOffsets" : 19,
    "getBatch" : 0,
    "latestOffset" : 9,
    "queryPlanning" : 18,
    "triggerExecution" : 3794,
    "walCommit" : 34
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 0
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 1
      }
    },
    "latestOffset" : null,
    "numInputRows" : 3,
    "inputRowsPerSecond" : 0.6,
    "processedRowsPerSecond" : 0.790722192936215
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
24/09/13 02:43:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/2 using temp file file:/tmp/checkpoint/offsets/.2.da1f2d0e-8b61-4c94-a367-6e78b89a6299.tmp
24/09/13 02:43:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.2.da1f2d0e-8b61-4c94-a367-6e78b89a6299.tmp to file:/tmp/checkpoint/offsets/2
24/09/13 02:43:15 INFO MicroBatchExecution: Committed offsets for batch 2. Metadata OffsetSeqMetadata(0,1726195395016,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:15,091 - INFO - Received command c on object id p0
24/09/13 02:43:15 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:15 INFO DAGScheduler: Got job 3 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:15 INFO DAGScheduler: Final stage: ResultStage 3 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:15 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:15 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:15 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[24] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 42.8 KiB, free 434.3 MiB)
24/09/13 02:43:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.3 MiB)
24/09/13 02:43:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[24] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
24/09/13 02:43:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 560 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/09/13 02:43:15 INFO DAGScheduler: ResultStage 3 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.565 s
24/09/13 02:43:15 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
24/09/13 02:43:15 INFO DAGScheduler: Job 3 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.568703 s
2024-09-13 02:43:15,681 - INFO - Processing batch 2
2024-09-13 02:43:15,681 - INFO - Batch content:
24/09/13 02:43:15 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:15 INFO DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:15 INFO DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:15 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:15 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:15 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[26] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
24/09/13 02:43:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 565 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/09/13 02:43:16 INFO DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 0.576 s
24/09/13 02:43:16 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/09/13 02:43:16 INFO DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 0.578304 s
+----+----------+---------+------+----------------------------------------------------------+---------+-----------------------+---------+------------------------+------------------------+------------+-------------------------------------------------+
|id  |first_name|last_name|gender|address                                                   |post_code|email                  |username |dob                     |registered_date         |phone       |picture                                          |
+----+----------+---------+------+----------------------------------------------------------+---------+-----------------------+---------+------------------------+------------------------+------------+-------------------------------------------------+
|NULL|Cody      |Lawson   |male  |4174 Northaven Rd, Adelaide, Northern Territory, Australia|9041     |cody.lawson@example.com|redcat838|1986-02-13T15:32:52.267Z|2019-06-09T05:35:13.970Z|01-1909-7629|https://randomuser.me/api/portraits/med/men/0.jpg|
+----+----------+---------+------+----------------------------------------------------------+---------+-----------------------+---------+------------------------+------------------------+------------+-------------------------------------------------+

24/09/13 02:43:16 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:16 INFO DAGScheduler: Got job 5 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:16 INFO DAGScheduler: Final stage: ResultStage 5 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:16 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:16 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[28] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:43:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:43:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[28] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
24/09/13 02:43:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 546 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/09/13 02:43:16 INFO DAGScheduler: ResultStage 5 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.551 s
24/09/13 02:43:16 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
24/09/13 02:43:16 INFO DAGScheduler: Job 5 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.554625 s
2024-09-13 02:43:16,893 - INFO - Inserting data: {'id': None, 'first_name': 'Cody', 'last_name': 'Lawson', 'gender': 'male', 'address': '4174 Northaven Rd, Adelaide, Northern Territory, Australia', 'post_code': '9041', 'email': 'cody.lawson@example.com', 'username': 'redcat838', 'dob': '1986-02-13T15:32:52.267Z', 'registered_date': '2019-06-09T05:35:13.970Z', 'phone': '01-1909-7629', 'picture': 'https://randomuser.me/api/portraits/med/men/0.jpg'}
2024-09-13 02:43:16,899 - INFO - Data inserted for Cody Lawson with ID e057054a-e606-47e4-bac8-7ff6cbd757e3
2024-09-13 02:43:16,899 - INFO - Successfully inserted data for Cody Lawson
2024-09-13 02:43:16,899 - INFO - Finished processing batch 2
24/09/13 02:43:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/2 using temp file file:/tmp/checkpoint/commits/.2.a8194846-d885-49be-a5ba-d48b9c8582c0.tmp
24/09/13 02:43:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.2.a8194846-d885-49be-a5ba-d48b9c8582c0.tmp to file:/tmp/checkpoint/commits/2
24/09/13 02:43:16 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:15.010Z",
  "batchId" : 2,
  "numInputRows" : 3,
  "inputRowsPerSecond" : 0.5990415335463258,
  "processedRowsPerSecond" : 1.5731515469323545,
  "durationMs" : {
    "addBatch" : 1837,
    "commitOffsets" : 18,
    "getBatch" : 0,
    "latestOffset" : 6,
    "queryPlanning" : 21,
    "triggerExecution" : 1907,
    "walCommit" : 22
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 1
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 2
      }
    },
    "latestOffset" : null,
    "numInputRows" : 3,
    "inputRowsPerSecond" : 0.5990415335463258,
    "processedRowsPerSecond" : 1.5731515469323545
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/3 using temp file file:/tmp/checkpoint/offsets/.3.138e3520-bdaf-43e8-9c06-03ab6b91312d.tmp
24/09/13 02:43:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.3.138e3520-bdaf-43e8-9c06-03ab6b91312d.tmp to file:/tmp/checkpoint/offsets/3
24/09/13 02:43:20 INFO MicroBatchExecution: Committed offsets for batch 3. Metadata OffsetSeqMetadata(0,1726195400020,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:20,065 - INFO - Received command c on object id p0
24/09/13 02:43:20 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:20 INFO DAGScheduler: Got job 6 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:20 INFO DAGScheduler: Final stage: ResultStage 6 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:20 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:20 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:20 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[35] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:43:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:43:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[35] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
24/09/13 02:43:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 553 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/09/13 02:43:20 INFO DAGScheduler: ResultStage 6 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.559 s
24/09/13 02:43:20 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
24/09/13 02:43:20 INFO DAGScheduler: Job 6 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.560610 s
2024-09-13 02:43:20,639 - INFO - Processing batch 3
2024-09-13 02:43:20,639 - INFO - Batch content:
24/09/13 02:43:20 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:20 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:20 INFO DAGScheduler: Final stage: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:20 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:20 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:20 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[37] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:20 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:20 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:20 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:20 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[37] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
24/09/13 02:43:20 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:20 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:20 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:21 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 559 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:21 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
24/09/13 02:43:21 INFO DAGScheduler: ResultStage 7 (showString at NativeMethodAccessorImpl.java:0) finished in 0.569 s
24/09/13 02:43:21 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
24/09/13 02:43:21 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0.571341 s
+----+----------+---------+------+---------------------------------------------------------+---------+--------------------------+------------+------------------------+------------------------+------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                  |post_code|email                     |username    |dob                     |registered_date         |phone       |picture                                             |
+----+----------+---------+------+---------------------------------------------------------+---------+--------------------------+------------+------------------------+------------------------+------------+----------------------------------------------------+
|NULL|     |     |male  |6340  , , , Iran            |30071    |prs.khwty@example.com     |tinyfrog429 |1998-03-14T16:10:47.368Z|2021-05-29T22:03:50.342Z|036-86417753|https://randomuser.me/api/portraits/med/men/62.jpg  |
|NULL|Diego     |Vicente  |male  |1669 Calle Covadonga, Alcal de Henares, Cantabria, Spain|86858    |diego.vicente@example.com |tinykoala800|1990-03-22T07:20:19.181Z|2018-08-24T01:59:46.624Z|975-824-934 |https://randomuser.me/api/portraits/med/men/62.jpg  |
|NULL|Sonja     |Reinartz |female|1047 Mhlenstrae, Wildberg, Saarland, Germany           |29925    |sonja.reinartz@example.com|sadmouse962 |1986-11-21T01:01:14.043Z|2003-08-27T16:06:36.565Z|0595-8235151|https://randomuser.me/api/portraits/med/women/48.jpg|
+----+----------+---------+------+---------------------------------------------------------+---------+--------------------------+------------+------------------------+------------------------+------------+----------------------------------------------------+

24/09/13 02:43:21 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:21 INFO DAGScheduler: Got job 8 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:21 INFO DAGScheduler: Final stage: ResultStage 8 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:21 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:21 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:21 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[39] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:43:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:43:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:21 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[39] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:21 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
24/09/13 02:43:21 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:21 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 557 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
24/09/13 02:43:21 INFO DAGScheduler: ResultStage 8 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.562 s
24/09/13 02:43:21 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
24/09/13 02:43:21 INFO DAGScheduler: Job 8 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.564966 s
2024-09-13 02:43:21,842 - INFO - Inserting data: {'id': None, 'first_name': '', 'last_name': '', 'gender': 'male', 'address': '6340  \u200c, \u200c, , Iran', 'post_code': '30071', 'email': 'prs.khwty@example.com', 'username': 'tinyfrog429', 'dob': '1998-03-14T16:10:47.368Z', 'registered_date': '2021-05-29T22:03:50.342Z', 'phone': '036-86417753', 'picture': 'https://randomuser.me/api/portraits/med/men/62.jpg'}
2024-09-13 02:43:21,849 - INFO - Data inserted for   with ID 20320da4-b330-42f2-bbdc-51184f493b68
2024-09-13 02:43:21,849 - INFO - Successfully inserted data for  
2024-09-13 02:43:21,849 - INFO - Inserting data: {'id': None, 'first_name': 'Diego', 'last_name': 'Vicente', 'gender': 'male', 'address': '1669 Calle Covadonga, Alcal de Henares, Cantabria, Spain', 'post_code': '86858', 'email': 'diego.vicente@example.com', 'username': 'tinykoala800', 'dob': '1990-03-22T07:20:19.181Z', 'registered_date': '2018-08-24T01:59:46.624Z', 'phone': '975-824-934', 'picture': 'https://randomuser.me/api/portraits/med/men/62.jpg'}
2024-09-13 02:43:21,852 - INFO - Data inserted for Diego Vicente with ID 4d9daf29-939a-44a2-a1e5-f736c1cbb4d8
2024-09-13 02:43:21,852 - INFO - Successfully inserted data for Diego Vicente
2024-09-13 02:43:21,852 - INFO - Inserting data: {'id': None, 'first_name': 'Sonja', 'last_name': 'Reinartz', 'gender': 'female', 'address': '1047 Mhlenstrae, Wildberg, Saarland, Germany', 'post_code': '29925', 'email': 'sonja.reinartz@example.com', 'username': 'sadmouse962', 'dob': '1986-11-21T01:01:14.043Z', 'registered_date': '2003-08-27T16:06:36.565Z', 'phone': '0595-8235151', 'picture': 'https://randomuser.me/api/portraits/med/women/48.jpg'}
2024-09-13 02:43:21,856 - INFO - Data inserted for Sonja Reinartz with ID d3984538-5cff-4a8c-8bb2-0021bf7e493b
2024-09-13 02:43:21,856 - INFO - Successfully inserted data for Sonja Reinartz
2024-09-13 02:43:21,856 - INFO - Finished processing batch 3
24/09/13 02:43:21 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/3 using temp file file:/tmp/checkpoint/commits/.3.a750cad2-7d7d-4d28-822e-419835ffc3c6.tmp
24/09/13 02:43:21 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.3.a750cad2-7d7d-4d28-822e-419835ffc3c6.tmp to file:/tmp/checkpoint/commits/3
24/09/13 02:43:21 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:20.003Z",
  "batchId" : 3,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4019627478469856,
  "processedRowsPerSecond" : 3.7433155080213902,
  "durationMs" : {
    "addBatch" : 1810,
    "commitOffsets" : 16,
    "getBatch" : 0,
    "latestOffset" : 16,
    "queryPlanning" : 10,
    "triggerExecution" : 1870,
    "walCommit" : 16
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 2
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 5
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4019627478469856,
    "processedRowsPerSecond" : 3.7433155080213902
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/4 using temp file file:/tmp/checkpoint/offsets/.4.b7225c44-498f-41aa-8735-5ab9c9d3d42b.tmp
24/09/13 02:43:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.4.b7225c44-498f-41aa-8735-5ab9c9d3d42b.tmp to file:/tmp/checkpoint/offsets/4
24/09/13 02:43:25 INFO MicroBatchExecution: Committed offsets for batch 4. Metadata OffsetSeqMetadata(0,1726195405008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:25,063 - INFO - Received command c on object id p0
24/09/13 02:43:25 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:25 INFO DAGScheduler: Got job 9 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:25 INFO DAGScheduler: Final stage: ResultStage 9 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:25 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:25 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:25 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:25 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:43:25 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:43:25 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:25 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
24/09/13 02:43:25 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:25 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 22 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:25 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
24/09/13 02:43:25 INFO DAGScheduler: ResultStage 9 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.026 s
24/09/13 02:43:25 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
24/09/13 02:43:25 INFO DAGScheduler: Job 9 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.029485 s
2024-09-13 02:43:25,105 - INFO - Processing batch 4
2024-09-13 02:43:25,105 - INFO - Batch content:
24/09/13 02:43:25 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:25 INFO DAGScheduler: Got job 10 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:25 INFO DAGScheduler: Final stage: ResultStage 10 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:25 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:25 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:25 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[48] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:25 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:25 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:25 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:25 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
24/09/13 02:43:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 555 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:25 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
24/09/13 02:43:25 INFO DAGScheduler: ResultStage 10 (showString at NativeMethodAccessorImpl.java:0) finished in 0.584 s
24/09/13 02:43:25 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
24/09/13 02:43:25 INFO DAGScheduler: Job 10 finished: showString at NativeMethodAccessorImpl.java:0, took 0.587075 s
+----+----------+---------+------+-------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                      |post_code|email                       |username         |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+-------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Deniz     |Samanc  |female|2331 Badat Cd, Bartn, Tunceli, Turkey                      |16661    |deniz.samanci@example.com   |angrybutterfly815|1947-04-06T22:35:29.179Z|2002-09-01T18:11:36.159Z|(280)-758-4599|https://randomuser.me/api/portraits/med/women/51.jpg|
|NULL|Klaus-D.  |Gericke  |male  |2097 Goethestrae, Volkach, Sachsen-Anhalt, Germany          |13163    |klaus-d..gericke@example.com|organicmouse502  |1945-04-22T03:44:20.857Z|2015-03-08T20:07:08.556Z|0103-9975935  |https://randomuser.me/api/portraits/med/men/3.jpg   |
|NULL|Lonie    |Leclercq |female|1479 Rue du Bt-D'Argent, Fort-de-France, Deux-Svres, France|82654    |leonie.leclercq@example.com |angrywolf351     |1994-10-07T14:04:08.161Z|2007-07-14T16:41:15.080Z|05-15-23-54-88|https://randomuser.me/api/portraits/med/women/94.jpg|
|NULL|Pilar     |Moreno   |female|5601 Calle de Segovia, Sevilla, Melilla, Spain               |74235    |pilar.moreno@example.com    |happygorilla299  |1955-09-27T16:04:37.799Z|2013-03-16T05:09:11.537Z|974-742-916   |https://randomuser.me/api/portraits/med/women/13.jpg|
+----+----------+---------+------+-------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:43:25 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:25 INFO DAGScheduler: Got job 11 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:25 INFO DAGScheduler: Final stage: ResultStage 11 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:25 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:25 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:25 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[50] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:25 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:43:25 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:43:25 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:25 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:25 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
24/09/13 02:43:25 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:25 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:26 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 530 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:26 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
24/09/13 02:43:26 INFO DAGScheduler: ResultStage 11 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.536 s
24/09/13 02:43:26 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
24/09/13 02:43:26 INFO DAGScheduler: Job 11 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.538736 s
2024-09-13 02:43:26,276 - INFO - Inserting data: {'id': None, 'first_name': 'Deniz', 'last_name': 'Samanc', 'gender': 'female', 'address': '2331 Badat Cd, Bartn, Tunceli, Turkey', 'post_code': '16661', 'email': 'deniz.samanci@example.com', 'username': 'angrybutterfly815', 'dob': '1947-04-06T22:35:29.179Z', 'registered_date': '2002-09-01T18:11:36.159Z', 'phone': '(280)-758-4599', 'picture': 'https://randomuser.me/api/portraits/med/women/51.jpg'}
2024-09-13 02:43:26,280 - INFO - Data inserted for Deniz Samanc with ID 2d6d9117-6e31-4bb4-acbd-7364b9e9d138
2024-09-13 02:43:26,280 - INFO - Successfully inserted data for Deniz Samanc
2024-09-13 02:43:26,280 - INFO - Inserting data: {'id': None, 'first_name': 'Klaus-D.', 'last_name': 'Gericke', 'gender': 'male', 'address': '2097 Goethestrae, Volkach, Sachsen-Anhalt, Germany', 'post_code': '13163', 'email': 'klaus-d..gericke@example.com', 'username': 'organicmouse502', 'dob': '1945-04-22T03:44:20.857Z', 'registered_date': '2015-03-08T20:07:08.556Z', 'phone': '0103-9975935', 'picture': 'https://randomuser.me/api/portraits/med/men/3.jpg'}
2024-09-13 02:43:26,284 - INFO - Data inserted for Klaus-D. Gericke with ID 84a49bc9-51f9-417a-82e9-23305e988865
2024-09-13 02:43:26,284 - INFO - Successfully inserted data for Klaus-D. Gericke
2024-09-13 02:43:26,284 - INFO - Inserting data: {'id': None, 'first_name': 'Lonie', 'last_name': 'Leclercq', 'gender': 'female', 'address': "1479 Rue du Bt-D'Argent, Fort-de-France, Deux-Svres, France", 'post_code': '82654', 'email': 'leonie.leclercq@example.com', 'username': 'angrywolf351', 'dob': '1994-10-07T14:04:08.161Z', 'registered_date': '2007-07-14T16:41:15.080Z', 'phone': '05-15-23-54-88', 'picture': 'https://randomuser.me/api/portraits/med/women/94.jpg'}
2024-09-13 02:43:26,287 - INFO - Data inserted for Lonie Leclercq with ID 6ee27f06-287b-407b-8f68-46350f2c6d3c
2024-09-13 02:43:26,287 - INFO - Successfully inserted data for Lonie Leclercq
2024-09-13 02:43:26,287 - INFO - Inserting data: {'id': None, 'first_name': 'Pilar', 'last_name': 'Moreno', 'gender': 'female', 'address': '5601 Calle de Segovia, Sevilla, Melilla, Spain', 'post_code': '74235', 'email': 'pilar.moreno@example.com', 'username': 'happygorilla299', 'dob': '1955-09-27T16:04:37.799Z', 'registered_date': '2013-03-16T05:09:11.537Z', 'phone': '974-742-916', 'picture': 'https://randomuser.me/api/portraits/med/women/13.jpg'}
2024-09-13 02:43:26,290 - INFO - Data inserted for Pilar Moreno with ID f27c9e18-529d-465c-a67b-d807d2b40db7
2024-09-13 02:43:26,290 - INFO - Successfully inserted data for Pilar Moreno
2024-09-13 02:43:26,290 - INFO - Finished processing batch 4
24/09/13 02:43:26 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/4 using temp file file:/tmp/checkpoint/commits/.4.aec51ac3-c226-4cf0-8faf-592dab1c2a2e.tmp
24/09/13 02:43:26 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.4.aec51ac3-c226-4cf0-8faf-592dab1c2a2e.tmp to file:/tmp/checkpoint/commits/4
24/09/13 02:43:26 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:25.001Z",
  "batchId" : 4,
  "numInputRows" : 9,
  "inputRowsPerSecond" : 1.800720288115246,
  "processedRowsPerSecond" : 6.901840490797546,
  "durationMs" : {
    "addBatch" : 1245,
    "commitOffsets" : 15,
    "getBatch" : 0,
    "latestOffset" : 6,
    "queryPlanning" : 14,
    "triggerExecution" : 1304,
    "walCommit" : 21
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 5
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 9
      }
    },
    "latestOffset" : null,
    "numInputRows" : 9,
    "inputRowsPerSecond" : 1.800720288115246,
    "processedRowsPerSecond" : 6.901840490797546
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/5 using temp file file:/tmp/checkpoint/offsets/.5.7a24598a-3840-434c-9110-b320acd14108.tmp
24/09/13 02:43:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.5.7a24598a-3840-434c-9110-b320acd14108.tmp to file:/tmp/checkpoint/offsets/5
24/09/13 02:43:30 INFO MicroBatchExecution: Committed offsets for batch 5. Metadata OffsetSeqMetadata(0,1726195410018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:30,085 - INFO - Received command c on object id p0
24/09/13 02:43:30 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:30 INFO DAGScheduler: Got job 12 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:30 INFO DAGScheduler: Final stage: ResultStage 12 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:30 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:30 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:30 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[57] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:30 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:43:30 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[57] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:30 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
24/09/13 02:43:30 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:30 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 527 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:30 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
24/09/13 02:43:30 INFO DAGScheduler: ResultStage 12 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.532 s
24/09/13 02:43:30 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
24/09/13 02:43:30 INFO DAGScheduler: Job 12 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.535413 s
2024-09-13 02:43:30,634 - INFO - Processing batch 5
2024-09-13 02:43:30,634 - INFO - Batch content:
24/09/13 02:43:30 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:30 INFO DAGScheduler: Got job 13 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:30 INFO DAGScheduler: Final stage: ResultStage 13 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:30 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:30 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:30 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[59] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:30 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:30 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[59] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:30 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
24/09/13 02:43:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 202 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:30 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
24/09/13 02:43:30 INFO DAGScheduler: ResultStage 13 (showString at NativeMethodAccessorImpl.java:0) finished in 0.211 s
24/09/13 02:43:30 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
24/09/13 02:43:30 INFO DAGScheduler: Job 13 finished: showString at NativeMethodAccessorImpl.java:0, took 0.213832 s
+----+-----------+---------+------+-----------------------------------------------------------------+---------+-----------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name |last_name|gender|address                                                          |post_code|email                        |username        |dob                     |registered_date         |phone         |picture                                             |
+----+-----------+---------+------+-----------------------------------------------------------------+---------+-----------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Jean-Daniel|Blanc    |male  |2705 Avenue des Ternes, Aigle, Schaffhausen, Switzerland         |4498     |jean-daniel.blanc@example.com|bigbear756      |1954-08-05T00:56:30.683Z|2009-02-22T18:36:33.692Z|079 141 52 30 |https://randomuser.me/api/portraits/med/men/46.jpg  |
|NULL|Noelia     |Murillo  |female|9275 Diagonal Oaxaca, San Pedro Tesistn, Baja California, Mexico|54800    |noelia.murillo@example.com   |redlion312      |1955-07-31T12:00:11.042Z|2015-10-14T20:04:52.477Z|(641) 214 3052|https://randomuser.me/api/portraits/med/women/21.jpg|
|NULL|Berdien    |Daane    |female|913 Eppenzolderbrink, Ugchelen, Limburg, Netherlands             |4905 TH  |berdien.daane@example.com    |beautifulduck214|1974-10-21T05:51:29.136Z|2008-11-27T05:29:35.845Z|(015) 7106672 |https://randomuser.me/api/portraits/med/women/3.jpg |
+----+-----------+---------+------+-----------------------------------------------------------------+---------+-----------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:43:30 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:30 INFO DAGScheduler: Got job 14 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:30 INFO DAGScheduler: Final stage: ResultStage 14 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:30 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:30 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:30 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:30 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:43:30 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:43:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:30 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:30 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
24/09/13 02:43:30 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:31 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 525 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:31 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
24/09/13 02:43:31 INFO DAGScheduler: ResultStage 14 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.529 s
24/09/13 02:43:31 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
24/09/13 02:43:31 INFO DAGScheduler: Job 14 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.531417 s
2024-09-13 02:43:31,418 - INFO - Inserting data: {'id': None, 'first_name': 'Jean-Daniel', 'last_name': 'Blanc', 'gender': 'male', 'address': '2705 Avenue des Ternes, Aigle, Schaffhausen, Switzerland', 'post_code': '4498', 'email': 'jean-daniel.blanc@example.com', 'username': 'bigbear756', 'dob': '1954-08-05T00:56:30.683Z', 'registered_date': '2009-02-22T18:36:33.692Z', 'phone': '079 141 52 30', 'picture': 'https://randomuser.me/api/portraits/med/men/46.jpg'}
2024-09-13 02:43:31,422 - INFO - Data inserted for Jean-Daniel Blanc with ID 8422947e-6faa-46d7-a0a1-23adb06a3bfd
2024-09-13 02:43:31,422 - INFO - Successfully inserted data for Jean-Daniel Blanc
2024-09-13 02:43:31,422 - INFO - Inserting data: {'id': None, 'first_name': 'Noelia', 'last_name': 'Murillo', 'gender': 'female', 'address': '9275 Diagonal Oaxaca, San Pedro Tesistn, Baja California, Mexico', 'post_code': '54800', 'email': 'noelia.murillo@example.com', 'username': 'redlion312', 'dob': '1955-07-31T12:00:11.042Z', 'registered_date': '2015-10-14T20:04:52.477Z', 'phone': '(641) 214 3052', 'picture': 'https://randomuser.me/api/portraits/med/women/21.jpg'}
2024-09-13 02:43:31,426 - INFO - Data inserted for Noelia Murillo with ID 0257ad77-c668-4821-a731-d9e41ea0c6c2
2024-09-13 02:43:31,426 - INFO - Successfully inserted data for Noelia Murillo
2024-09-13 02:43:31,426 - INFO - Inserting data: {'id': None, 'first_name': 'Berdien', 'last_name': 'Daane', 'gender': 'female', 'address': '913 Eppenzolderbrink, Ugchelen, Limburg, Netherlands', 'post_code': '4905 TH', 'email': 'berdien.daane@example.com', 'username': 'beautifulduck214', 'dob': '1974-10-21T05:51:29.136Z', 'registered_date': '2008-11-27T05:29:35.845Z', 'phone': '(015) 7106672', 'picture': 'https://randomuser.me/api/portraits/med/women/3.jpg'}
2024-09-13 02:43:31,428 - INFO - Data inserted for Berdien Daane with ID 5169695d-4e8b-4557-a996-37f1c91fdfe2
2024-09-13 02:43:31,429 - INFO - Successfully inserted data for Berdien Daane
2024-09-13 02:43:31,429 - INFO - Finished processing batch 5
24/09/13 02:43:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/5 using temp file file:/tmp/checkpoint/commits/.5.28d9d826-e6e0-47e4-a7ae-1daf7951fc11.tmp
24/09/13 02:43:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.5.28d9d826-e6e0-47e4-a7ae-1daf7951fc11.tmp to file:/tmp/checkpoint/commits/5
24/09/13 02:43:31 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:30.004Z",
  "batchId" : 5,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.3991605036977812,
  "processedRowsPerSecond" : 4.861111111111112,
  "durationMs" : {
    "addBatch" : 1365,
    "commitOffsets" : 15,
    "getBatch" : 0,
    "latestOffset" : 12,
    "queryPlanning" : 16,
    "triggerExecution" : 1440,
    "walCommit" : 27
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 9
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 12
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.3991605036977812,
    "processedRowsPerSecond" : 4.861111111111112
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/6 using temp file file:/tmp/checkpoint/offsets/.6.acbcff88-6338-41a8-859e-6c9a682aae9b.tmp
24/09/13 02:43:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.6.acbcff88-6338-41a8-859e-6c9a682aae9b.tmp to file:/tmp/checkpoint/offsets/6
24/09/13 02:43:35 INFO MicroBatchExecution: Committed offsets for batch 6. Metadata OffsetSeqMetadata(0,1726195415008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:35,072 - INFO - Received command c on object id p0
24/09/13 02:43:35 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:35 INFO DAGScheduler: Got job 15 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:35 INFO DAGScheduler: Final stage: ResultStage 15 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:35 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:35 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:35 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[68] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:35 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:43:35 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:43:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[68] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:35 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
24/09/13 02:43:35 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 317 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:35 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
24/09/13 02:43:35 INFO DAGScheduler: ResultStage 15 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.321 s
24/09/13 02:43:35 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
24/09/13 02:43:35 INFO DAGScheduler: Job 15 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.323678 s
2024-09-13 02:43:35,409 - INFO - Processing batch 6
2024-09-13 02:43:35,409 - INFO - Batch content:
24/09/13 02:43:35 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:35 INFO DAGScheduler: Got job 16 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:35 INFO DAGScheduler: Final stage: ResultStage 16 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:35 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:35 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:35 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:35 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:35 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:35 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:35 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
24/09/13 02:43:35 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:35 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:35 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 543 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:35 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
24/09/13 02:43:35 INFO DAGScheduler: ResultStage 16 (showString at NativeMethodAccessorImpl.java:0) finished in 0.553 s
24/09/13 02:43:35 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
24/09/13 02:43:35 INFO DAGScheduler: Job 16 finished: showString at NativeMethodAccessorImpl.java:0, took 0.554876 s
+----+----------+---------+------+---------------------------------------------------------+---------+------------------------+---------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                  |post_code|email                   |username       |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+---------------------------------------------------------+---------+------------------------+---------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Julia     |Ray      |female|7192 Station Road, Bristol, County Antrim, United Kingdom|KX7 2YQ  |julia.ray@example.com   |greenpeacock161|1944-10-16T23:34:46.697Z|2007-01-04T22:53:19.267Z|016977 3559   |https://randomuser.me/api/portraits/med/women/70.jpg|
|NULL|Tim       |Martin   |male  |6936 Rue du Chteau, Aix-En-Provence, Vienne, France     |13680    |tim.martin@example.com  |whitedog445    |1971-04-27T03:24:33.818Z|2002-05-01T13:20:47.512Z|04-18-27-04-68|https://randomuser.me/api/portraits/med/men/9.jpg   |
|NULL|Knut      |Gassner  |male  |5455 Bachstrae, Geisingen, Baden-Wrttemberg, Germany   |80694    |knut.gassner@example.com|brownpanda404  |1962-03-17T02:42:25.049Z|2017-07-09T18:36:38.040Z|0276-7859912  |https://randomuser.me/api/portraits/med/men/41.jpg  |
+----+----------+---------+------+---------------------------------------------------------+---------+------------------------+---------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:43:36 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:36 INFO DAGScheduler: Got job 17 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:36 INFO DAGScheduler: Final stage: ResultStage 17 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:36 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:36 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:36 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[72] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:36 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:43:36 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:43:36 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:36 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[72] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:36 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
24/09/13 02:43:36 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:36 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:36 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 554 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:36 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
24/09/13 02:43:36 INFO DAGScheduler: ResultStage 17 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.559 s
24/09/13 02:43:36 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
24/09/13 02:43:36 INFO DAGScheduler: Job 17 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.561850 s
2024-09-13 02:43:36,583 - INFO - Inserting data: {'id': None, 'first_name': 'Julia', 'last_name': 'Ray', 'gender': 'female', 'address': '7192 Station Road, Bristol, County Antrim, United Kingdom', 'post_code': 'KX7 2YQ', 'email': 'julia.ray@example.com', 'username': 'greenpeacock161', 'dob': '1944-10-16T23:34:46.697Z', 'registered_date': '2007-01-04T22:53:19.267Z', 'phone': '016977 3559', 'picture': 'https://randomuser.me/api/portraits/med/women/70.jpg'}
2024-09-13 02:43:36,590 - INFO - Data inserted for Julia Ray with ID ec83fa94-a3ba-4dd3-be82-624f5cb21841
2024-09-13 02:43:36,590 - INFO - Successfully inserted data for Julia Ray
2024-09-13 02:43:36,590 - INFO - Inserting data: {'id': None, 'first_name': 'Tim', 'last_name': 'Martin', 'gender': 'male', 'address': '6936 Rue du Chteau, Aix-En-Provence, Vienne, France', 'post_code': '13680', 'email': 'tim.martin@example.com', 'username': 'whitedog445', 'dob': '1971-04-27T03:24:33.818Z', 'registered_date': '2002-05-01T13:20:47.512Z', 'phone': '04-18-27-04-68', 'picture': 'https://randomuser.me/api/portraits/med/men/9.jpg'}
2024-09-13 02:43:36,595 - INFO - Data inserted for Tim Martin with ID 972be1fb-c8bb-437a-a721-bf539b9ee38c
2024-09-13 02:43:36,595 - INFO - Successfully inserted data for Tim Martin
2024-09-13 02:43:36,595 - INFO - Inserting data: {'id': None, 'first_name': 'Knut', 'last_name': 'Gassner', 'gender': 'male', 'address': '5455 Bachstrae, Geisingen, Baden-Wrttemberg, Germany', 'post_code': '80694', 'email': 'knut.gassner@example.com', 'username': 'brownpanda404', 'dob': '1962-03-17T02:42:25.049Z', 'registered_date': '2017-07-09T18:36:38.040Z', 'phone': '0276-7859912', 'picture': 'https://randomuser.me/api/portraits/med/men/41.jpg'}
2024-09-13 02:43:36,599 - INFO - Data inserted for Knut Gassner with ID 7cf31a8d-79bd-4f40-bac4-4f394a9ba29b
2024-09-13 02:43:36,599 - INFO - Successfully inserted data for Knut Gassner
2024-09-13 02:43:36,599 - INFO - Finished processing batch 6
24/09/13 02:43:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/6 using temp file file:/tmp/checkpoint/commits/.6.2dabfe4b-08e2-4cbd-bef1-013a7339424c.tmp
24/09/13 02:43:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.6.2dabfe4b-08e2-4cbd-bef1-013a7339424c.tmp to file:/tmp/checkpoint/commits/6
24/09/13 02:43:36 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:35.001Z",
  "batchId" : 6,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4008405043025816,
  "processedRowsPerSecond" : 4.3316831683168315,
  "durationMs" : {
    "addBatch" : 1547,
    "commitOffsets" : 18,
    "getBatch" : 0,
    "latestOffset" : 7,
    "queryPlanning" : 14,
    "triggerExecution" : 1616,
    "walCommit" : 28
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 12
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 15
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4008405043025816,
    "processedRowsPerSecond" : 4.3316831683168315
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:40 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/7 using temp file file:/tmp/checkpoint/offsets/.7.bf086280-7ed6-4a1c-a36f-e71929ea4494.tmp
24/09/13 02:43:40 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.7.bf086280-7ed6-4a1c-a36f-e71929ea4494.tmp to file:/tmp/checkpoint/offsets/7
24/09/13 02:43:40 INFO MicroBatchExecution: Committed offsets for batch 7. Metadata OffsetSeqMetadata(0,1726195420017,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:40,070 - INFO - Received command c on object id p0
24/09/13 02:43:40 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:40 INFO DAGScheduler: Got job 18 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:40 INFO DAGScheduler: Final stage: ResultStage 18 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:40 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:40 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:40 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[79] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:40 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:43:40 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[79] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:40 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
24/09/13 02:43:40 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 23 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:40 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
24/09/13 02:43:40 INFO DAGScheduler: ResultStage 18 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.027 s
24/09/13 02:43:40 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
24/09/13 02:43:40 INFO DAGScheduler: Job 18 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.031879 s
2024-09-13 02:43:40,115 - INFO - Processing batch 7
2024-09-13 02:43:40,115 - INFO - Batch content:
24/09/13 02:43:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:40 INFO DAGScheduler: Got job 19 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:40 INFO DAGScheduler: Final stage: ResultStage 19 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:40 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:40 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:40 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[81] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:40 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:40 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[81] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:40 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
24/09/13 02:43:40 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:40 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 534 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:40 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
24/09/13 02:43:40 INFO DAGScheduler: ResultStage 19 (showString at NativeMethodAccessorImpl.java:0) finished in 0.544 s
24/09/13 02:43:40 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
24/09/13 02:43:40 INFO DAGScheduler: Job 19 finished: showString at NativeMethodAccessorImpl.java:0, took 0.546089 s
+----+----------+---------+------+-----------------------------------------------------+---------+-------------------------------+---------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                              |post_code|email                          |username       |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+-----------------------------------------------------+---------+-------------------------------+---------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Caleb     |Roberts  |male  |8456 Ward Street, Invercargill, Auckland, New Zealand|10302    |caleb.roberts@example.com      |happyladybug951|1956-07-18T21:04:16.736Z|2004-10-31T21:58:56.032Z|(588)-802-8523|https://randomuser.me/api/portraits/med/men/25.jpg  |
|NULL|Stefaniya |Lesevichi|female|6863 Medveckogo, Korec, Luganska, Ukraine            |25010    |stefaniya.lesevichi@example.com|sadpanda222    |1987-05-31T07:18:38.955Z|2017-04-01T00:52:13.292Z|(068) I53-3746|https://randomuser.me/api/portraits/med/women/57.jpg|
|NULL|Villemo   |Systad   |female|8343 Steinborgveien, Moane, Buskerud, Norway         |3004     |villemo.systad@example.com     |sadduck320     |1982-10-08T22:28:00.197Z|2006-08-09T06:50:37.144Z|71504303      |https://randomuser.me/api/portraits/med/women/83.jpg|
|NULL|Azar      |Klochko  |male  |1066 Berislavske shose, Derazhnya, Vinnicka, Ukraine |74741    |azar.klochko@example.com       |blackwolf143   |1983-06-07T15:01:59.798Z|2020-07-07T02:27:06.356Z|(096) K49-9531|https://randomuser.me/api/portraits/med/men/68.jpg  |
+----+----------+---------+------+-----------------------------------------------------+---------+-------------------------------+---------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:43:40 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:40 INFO DAGScheduler: Got job 20 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:40 INFO DAGScheduler: Final stage: ResultStage 20 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:40 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:40 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:40 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[83] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:40 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:43:40 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:43:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:40 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[83] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:40 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
24/09/13 02:43:40 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:41 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 541 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:41 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
24/09/13 02:43:41 INFO DAGScheduler: ResultStage 20 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.545 s
24/09/13 02:43:41 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
24/09/13 02:43:41 INFO DAGScheduler: Job 20 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.547016 s
2024-09-13 02:43:41,252 - INFO - Inserting data: {'id': None, 'first_name': 'Caleb', 'last_name': 'Roberts', 'gender': 'male', 'address': '8456 Ward Street, Invercargill, Auckland, New Zealand', 'post_code': '10302', 'email': 'caleb.roberts@example.com', 'username': 'happyladybug951', 'dob': '1956-07-18T21:04:16.736Z', 'registered_date': '2004-10-31T21:58:56.032Z', 'phone': '(588)-802-8523', 'picture': 'https://randomuser.me/api/portraits/med/men/25.jpg'}
2024-09-13 02:43:41,256 - INFO - Data inserted for Caleb Roberts with ID 6a37452e-f148-4ef1-b6f2-af5512dfa3b0
2024-09-13 02:43:41,257 - INFO - Successfully inserted data for Caleb Roberts
2024-09-13 02:43:41,257 - INFO - Inserting data: {'id': None, 'first_name': 'Stefaniya', 'last_name': 'Lesevichi', 'gender': 'female', 'address': '6863 Medveckogo, Korec, Luganska, Ukraine', 'post_code': '25010', 'email': 'stefaniya.lesevichi@example.com', 'username': 'sadpanda222', 'dob': '1987-05-31T07:18:38.955Z', 'registered_date': '2017-04-01T00:52:13.292Z', 'phone': '(068) I53-3746', 'picture': 'https://randomuser.me/api/portraits/med/women/57.jpg'}
2024-09-13 02:43:41,262 - INFO - Data inserted for Stefaniya Lesevichi with ID a122799b-08e0-44ca-9f92-9bbe24c8b274
2024-09-13 02:43:41,262 - INFO - Successfully inserted data for Stefaniya Lesevichi
2024-09-13 02:43:41,262 - INFO - Inserting data: {'id': None, 'first_name': 'Villemo', 'last_name': 'Systad', 'gender': 'female', 'address': '8343 Steinborgveien, Moane, Buskerud, Norway', 'post_code': '3004', 'email': 'villemo.systad@example.com', 'username': 'sadduck320', 'dob': '1982-10-08T22:28:00.197Z', 'registered_date': '2006-08-09T06:50:37.144Z', 'phone': '71504303', 'picture': 'https://randomuser.me/api/portraits/med/women/83.jpg'}
2024-09-13 02:43:41,266 - INFO - Data inserted for Villemo Systad with ID 8a7a8c2f-9e72-4487-933c-84a85d290b0b
2024-09-13 02:43:41,266 - INFO - Successfully inserted data for Villemo Systad
2024-09-13 02:43:41,266 - INFO - Inserting data: {'id': None, 'first_name': 'Azar', 'last_name': 'Klochko', 'gender': 'male', 'address': '1066 Berislavske shose, Derazhnya, Vinnicka, Ukraine', 'post_code': '74741', 'email': 'azar.klochko@example.com', 'username': 'blackwolf143', 'dob': '1983-06-07T15:01:59.798Z', 'registered_date': '2020-07-07T02:27:06.356Z', 'phone': '(096) K49-9531', 'picture': 'https://randomuser.me/api/portraits/med/men/68.jpg'}
2024-09-13 02:43:41,269 - INFO - Data inserted for Azar Klochko with ID 1e84f6ed-41d6-4385-96f1-77dda8b4aaf7
2024-09-13 02:43:41,269 - INFO - Successfully inserted data for Azar Klochko
2024-09-13 02:43:41,269 - INFO - Finished processing batch 7
24/09/13 02:43:41 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/7 using temp file file:/tmp/checkpoint/commits/.7.4e7255fd-534a-43c9-96ba-9e8a87ac5dab.tmp
24/09/13 02:43:41 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.7.4e7255fd-534a-43c9-96ba-9e8a87ac5dab.tmp to file:/tmp/checkpoint/commits/7
24/09/13 02:43:41 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:40.002Z",
  "batchId" : 7,
  "numInputRows" : 9,
  "inputRowsPerSecond" : 1.7996400719856027,
  "processedRowsPerSecond" : 6.982156710628394,
  "durationMs" : {
    "addBatch" : 1220,
    "commitOffsets" : 21,
    "getBatch" : 0,
    "latestOffset" : 14,
    "queryPlanning" : 10,
    "triggerExecution" : 1289,
    "walCommit" : 21
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 15
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 19
      }
    },
    "latestOffset" : null,
    "numInputRows" : 9,
    "inputRowsPerSecond" : 1.7996400719856027,
    "processedRowsPerSecond" : 6.982156710628394
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:45 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/8 using temp file file:/tmp/checkpoint/offsets/.8.32b00bd9-f217-4174-8c4d-2bc1e79e883e.tmp
24/09/13 02:43:45 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.8.32b00bd9-f217-4174-8c4d-2bc1e79e883e.tmp to file:/tmp/checkpoint/offsets/8
24/09/13 02:43:45 INFO MicroBatchExecution: Committed offsets for batch 8. Metadata OffsetSeqMetadata(0,1726195425019,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:45,077 - INFO - Received command c on object id p0
24/09/13 02:43:45 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:45 INFO DAGScheduler: Got job 21 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:45 INFO DAGScheduler: Final stage: ResultStage 21 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:45 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:45 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:45 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[90] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:45 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:43:45 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:43:45 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[90] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:45 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
24/09/13 02:43:45 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:45 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 467 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:45 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
24/09/13 02:43:45 INFO DAGScheduler: ResultStage 21 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.472 s
24/09/13 02:43:45 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
24/09/13 02:43:45 INFO DAGScheduler: Job 21 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.475066 s
2024-09-13 02:43:45,563 - INFO - Processing batch 8
2024-09-13 02:43:45,563 - INFO - Batch content:
24/09/13 02:43:45 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:45 INFO DAGScheduler: Got job 22 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:45 INFO DAGScheduler: Final stage: ResultStage 22 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:45 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:45 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:45 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[92] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:45 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:45 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:45 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:45 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[92] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:45 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
24/09/13 02:43:45 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:45 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:45 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:46 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 527 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:46 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
24/09/13 02:43:46 INFO DAGScheduler: ResultStage 22 (showString at NativeMethodAccessorImpl.java:0) finished in 0.537 s
24/09/13 02:43:46 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
24/09/13 02:43:46 INFO DAGScheduler: Job 22 finished: showString at NativeMethodAccessorImpl.java:0, took 0.538876 s
+----+----------+---------+------+--------------------------------------------------------+---------+--------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                 |post_code|email                     |username        |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+--------------------------------------------------------+---------+--------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Emilio    |Pizarro  |male  |3864 Privada Tejada, Temosachi, Estado de Mexico, Mexico|49428    |emilio.pizarro@example.com|saddog725       |1973-04-08T23:02:28.018Z|2014-10-30T07:48:56.381Z|(659) 897 7760|https://randomuser.me/api/portraits/med/men/33.jpg  |
|NULL|Claire    |Bonnet   |female|5372 Rue Abel-Ferry, Schongau, Jura, Switzerland        |5618     |claire.bonnet@example.com |tinyzebra238    |1960-10-10T09:24:58.374Z|2009-06-28T02:25:11.018Z|076 677 58 18 |https://randomuser.me/api/portraits/med/women/72.jpg|
|NULL|Ellen     |Ramo     |female|2362 Satakennankatu, Suomussalmi, Pijt-Hme, Finland  |79311    |ellen.ramo@example.com    |goldenostrich875|1953-07-13T18:12:59.146Z|2007-04-06T15:57:41.229Z|09-926-868    |https://randomuser.me/api/portraits/med/women/13.jpg|
+----+----------+---------+------+--------------------------------------------------------+---------+--------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:43:46 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:46 INFO DAGScheduler: Got job 23 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:46 INFO DAGScheduler: Final stage: ResultStage 23 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:46 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:46 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:46 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[94] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:46 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:43:46 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:43:46 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:46 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[94] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:46 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
24/09/13 02:43:46 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:46 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:46 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 530 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:46 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
24/09/13 02:43:46 INFO DAGScheduler: ResultStage 23 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.535 s
24/09/13 02:43:46 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
24/09/13 02:43:46 INFO DAGScheduler: Job 23 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.537092 s
2024-09-13 02:43:46,686 - INFO - Inserting data: {'id': None, 'first_name': 'Emilio', 'last_name': 'Pizarro', 'gender': 'male', 'address': '3864 Privada Tejada, Temosachi, Estado de Mexico, Mexico', 'post_code': '49428', 'email': 'emilio.pizarro@example.com', 'username': 'saddog725', 'dob': '1973-04-08T23:02:28.018Z', 'registered_date': '2014-10-30T07:48:56.381Z', 'phone': '(659) 897 7760', 'picture': 'https://randomuser.me/api/portraits/med/men/33.jpg'}
2024-09-13 02:43:46,692 - INFO - Data inserted for Emilio Pizarro with ID e4b2a3ee-2073-4d95-835f-001195f7f8d6
2024-09-13 02:43:46,692 - INFO - Successfully inserted data for Emilio Pizarro
2024-09-13 02:43:46,692 - INFO - Inserting data: {'id': None, 'first_name': 'Claire', 'last_name': 'Bonnet', 'gender': 'female', 'address': '5372 Rue Abel-Ferry, Schongau, Jura, Switzerland', 'post_code': '5618', 'email': 'claire.bonnet@example.com', 'username': 'tinyzebra238', 'dob': '1960-10-10T09:24:58.374Z', 'registered_date': '2009-06-28T02:25:11.018Z', 'phone': '076 677 58 18', 'picture': 'https://randomuser.me/api/portraits/med/women/72.jpg'}
2024-09-13 02:43:46,696 - INFO - Data inserted for Claire Bonnet with ID b414f52e-6bcf-41ac-b0a4-889b32dc7050
2024-09-13 02:43:46,696 - INFO - Successfully inserted data for Claire Bonnet
2024-09-13 02:43:46,696 - INFO - Inserting data: {'id': None, 'first_name': 'Ellen', 'last_name': 'Ramo', 'gender': 'female', 'address': '2362 Satakennankatu, Suomussalmi, Pijt-Hme, Finland', 'post_code': '79311', 'email': 'ellen.ramo@example.com', 'username': 'goldenostrich875', 'dob': '1953-07-13T18:12:59.146Z', 'registered_date': '2007-04-06T15:57:41.229Z', 'phone': '09-926-868', 'picture': 'https://randomuser.me/api/portraits/med/women/13.jpg'}
2024-09-13 02:43:46,699 - INFO - Data inserted for Ellen Ramo with ID 727a38b3-3f92-4329-8964-5d1174fb913c
2024-09-13 02:43:46,699 - INFO - Successfully inserted data for Ellen Ramo
2024-09-13 02:43:46,699 - INFO - Finished processing batch 8
24/09/13 02:43:46 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/8 using temp file file:/tmp/checkpoint/commits/.8.6d0ca0fe-11d4-4696-82b6-c8a460d6bf5b.tmp
24/09/13 02:43:46 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.8.6d0ca0fe-11d4-4696-82b6-c8a460d6bf5b.tmp to file:/tmp/checkpoint/commits/8
24/09/13 02:43:46 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:45.002Z",
  "batchId" : 8,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4,
  "processedRowsPerSecond" : 4.084014002333722,
  "durationMs" : {
    "addBatch" : 1642,
    "commitOffsets" : 17,
    "getBatch" : 1,
    "latestOffset" : 17,
    "queryPlanning" : 12,
    "triggerExecution" : 1714,
    "walCommit" : 23
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 19
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 22
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4,
    "processedRowsPerSecond" : 4.084014002333722
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:50 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/9 using temp file file:/tmp/checkpoint/offsets/.9.353938d4-8679-480f-b652-26ee3b91a946.tmp
24/09/13 02:43:50 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.9.353938d4-8679-480f-b652-26ee3b91a946.tmp to file:/tmp/checkpoint/offsets/9
24/09/13 02:43:50 INFO MicroBatchExecution: Committed offsets for batch 9. Metadata OffsetSeqMetadata(0,1726195430016,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:50,065 - INFO - Received command c on object id p0
24/09/13 02:43:50 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:50 INFO DAGScheduler: Got job 24 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:50 INFO DAGScheduler: Final stage: ResultStage 24 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:50 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:50 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:50 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[101] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:50 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:43:50 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[101] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:50 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
24/09/13 02:43:50 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:50 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 17 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:50 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
24/09/13 02:43:50 INFO DAGScheduler: ResultStage 24 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.019 s
24/09/13 02:43:50 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
24/09/13 02:43:50 INFO DAGScheduler: Job 24 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.022064 s
2024-09-13 02:43:50,098 - INFO - Processing batch 9
2024-09-13 02:43:50,098 - INFO - Batch content:
24/09/13 02:43:50 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:50 INFO DAGScheduler: Got job 25 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:50 INFO DAGScheduler: Final stage: ResultStage 25 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:50 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:50 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:50 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[103] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:50 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:50 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:50 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[103] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:50 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
24/09/13 02:43:50 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:43:50 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 444 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:50 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
24/09/13 02:43:50 INFO DAGScheduler: ResultStage 25 (showString at NativeMethodAccessorImpl.java:0) finished in 0.448 s
24/09/13 02:43:50 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
24/09/13 02:43:50 INFO DAGScheduler: Job 25 finished: showString at NativeMethodAccessorImpl.java:0, took 0.449258 s
+----+----------+---------+------+------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                     |post_code|email                       |username         |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Patrick   |Edwards  |male  |405 North Street, Napier, Waikato, New Zealand              |31839    |patrick.edwards@example.com |smallbutterfly872|1946-11-19T22:58:35.630Z|2003-09-15T20:03:47.393Z|(557)-309-4996|https://randomuser.me/api/portraits/med/men/96.jpg  |
|NULL|Teodoro   |Limn    |male  |1765 Eje vial Mxico, El Pitahayal, Ciudad de Mexico, Mexico|79127    |teodoro.limon@example.com   |browngorilla975  |1996-06-09T03:36:08.935Z|2019-09-20T02:43:04.380Z|(618) 517 3128|https://randomuser.me/api/portraits/med/men/6.jpg   |
|NULL|Paulette  |Mercier  |female|5616 Rue de L'Abbaye, Novaggio, Schaffhausen, Switzerland   |3366     |paulette.mercier@example.com|silverdog318     |1976-01-12T07:27:34.106Z|2016-06-07T02:07:26.411Z|076 760 84 67 |https://randomuser.me/api/portraits/med/women/29.jpg|
+----+----------+---------+------+------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:43:50 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:50 INFO DAGScheduler: Got job 26 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:50 INFO DAGScheduler: Final stage: ResultStage 26 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:50 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:50 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:50 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[105] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:50 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 45.7 KiB, free 434.1 MiB)
24/09/13 02:43:50 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.1 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:43:50 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[105] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:50 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
24/09/13 02:43:50 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:50 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:51 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 570 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:51 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
24/09/13 02:43:51 INFO DAGScheduler: ResultStage 26 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.582 s
24/09/13 02:43:51 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
24/09/13 02:43:51 INFO DAGScheduler: Job 26 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.584945 s
2024-09-13 02:43:51,169 - INFO - Inserting data: {'id': None, 'first_name': 'Patrick', 'last_name': 'Edwards', 'gender': 'male', 'address': '405 North Street, Napier, Waikato, New Zealand', 'post_code': '31839', 'email': 'patrick.edwards@example.com', 'username': 'smallbutterfly872', 'dob': '1946-11-19T22:58:35.630Z', 'registered_date': '2003-09-15T20:03:47.393Z', 'phone': '(557)-309-4996', 'picture': 'https://randomuser.me/api/portraits/med/men/96.jpg'}
2024-09-13 02:43:51,173 - INFO - Data inserted for Patrick Edwards with ID 113b26d0-83bc-418e-b88c-3695bbc41173
2024-09-13 02:43:51,173 - INFO - Successfully inserted data for Patrick Edwards
2024-09-13 02:43:51,173 - INFO - Inserting data: {'id': None, 'first_name': 'Teodoro', 'last_name': 'Limn', 'gender': 'male', 'address': '1765 Eje vial Mxico, El Pitahayal, Ciudad de Mexico, Mexico', 'post_code': '79127', 'email': 'teodoro.limon@example.com', 'username': 'browngorilla975', 'dob': '1996-06-09T03:36:08.935Z', 'registered_date': '2019-09-20T02:43:04.380Z', 'phone': '(618) 517 3128', 'picture': 'https://randomuser.me/api/portraits/med/men/6.jpg'}
2024-09-13 02:43:51,176 - INFO - Data inserted for Teodoro Limn with ID 0689b3de-7b09-4439-b8bd-201e16288502
2024-09-13 02:43:51,176 - INFO - Successfully inserted data for Teodoro Limn
2024-09-13 02:43:51,177 - INFO - Inserting data: {'id': None, 'first_name': 'Paulette', 'last_name': 'Mercier', 'gender': 'female', 'address': "5616 Rue de L'Abbaye, Novaggio, Schaffhausen, Switzerland", 'post_code': '3366', 'email': 'paulette.mercier@example.com', 'username': 'silverdog318', 'dob': '1976-01-12T07:27:34.106Z', 'registered_date': '2016-06-07T02:07:26.411Z', 'phone': '076 760 84 67', 'picture': 'https://randomuser.me/api/portraits/med/women/29.jpg'}
2024-09-13 02:43:51,179 - INFO - Data inserted for Paulette Mercier with ID 5ca328c5-2d3a-4ffb-85c8-22abb2241ca6
2024-09-13 02:43:51,179 - INFO - Successfully inserted data for Paulette Mercier
2024-09-13 02:43:51,179 - INFO - Finished processing batch 9
24/09/13 02:43:51 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/9 using temp file file:/tmp/checkpoint/commits/.9.143f21e6-a308-4b3d-aaff-9f3db0478093.tmp
24/09/13 02:43:51 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.9.143f21e6-a308-4b3d-aaff-9f3db0478093.tmp to file:/tmp/checkpoint/commits/9
24/09/13 02:43:51 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:50.006Z",
  "batchId" : 9,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.398880895283773,
  "processedRowsPerSecond" : 5.8626465661641545,
  "durationMs" : {
    "addBatch" : 1130,
    "commitOffsets" : 20,
    "getBatch" : 1,
    "latestOffset" : 9,
    "queryPlanning" : 11,
    "triggerExecution" : 1194,
    "walCommit" : 21
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 22
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 25
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.398880895283773,
    "processedRowsPerSecond" : 5.8626465661641545
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:43:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/10 using temp file file:/tmp/checkpoint/offsets/.10.f76de1ce-ba9f-4af4-b0f5-bb7489a4b618.tmp
24/09/13 02:43:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.10.f76de1ce-ba9f-4af4-b0f5-bb7489a4b618.tmp to file:/tmp/checkpoint/offsets/10
24/09/13 02:43:55 INFO MicroBatchExecution: Committed offsets for batch 10. Metadata OffsetSeqMetadata(0,1726195435010,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:43:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:43:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:43:55,065 - INFO - Received command c on object id p0
24/09/13 02:43:55 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:43:55 INFO DAGScheduler: Got job 27 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:55 INFO DAGScheduler: Final stage: ResultStage 27 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:55 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:55 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:55 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:55 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 42.8 KiB, free 434.3 MiB)
24/09/13 02:43:55 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.3 MiB)
24/09/13 02:43:55 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:55 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:55 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
24/09/13 02:43:55 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:55 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:43:55 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 541 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:55 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
24/09/13 02:43:55 INFO DAGScheduler: ResultStage 27 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.553 s
24/09/13 02:43:55 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
24/09/13 02:43:55 INFO DAGScheduler: Job 27 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.557949 s
2024-09-13 02:43:55,637 - INFO - Processing batch 10
2024-09-13 02:43:55,637 - INFO - Batch content:
24/09/13 02:43:55 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:43:55 INFO DAGScheduler: Got job 28 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:43:55 INFO DAGScheduler: Final stage: ResultStage 28 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:43:55 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:55 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:55 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[114] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:43:55 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:43:55 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:43:55 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:55 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[114] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:55 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
24/09/13 02:43:55 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:55 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:43:56 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 550 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:56 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
24/09/13 02:43:56 INFO DAGScheduler: ResultStage 28 (showString at NativeMethodAccessorImpl.java:0) finished in 0.554 s
24/09/13 02:43:56 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
24/09/13 02:43:56 INFO DAGScheduler: Job 28 finished: showString at NativeMethodAccessorImpl.java:0, took 0.556191 s
+----+----------+---------+------+----------------------------------------------------------------+---------+-------------------------+--------------------+------------------------+------------------------+------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                         |post_code|email                    |username            |dob                     |registered_date         |phone       |picture                                             |
+----+----------+---------+------+----------------------------------------------------------------+---------+-------------------------+--------------------+------------------------+------------------------+------------+----------------------------------------------------+
|NULL|Noah      |Graham   |male  |4125 Camden Ave, Dubbo, New South Wales, Australia              |7398     |noah.graham@example.com  |silverzebra813      |1990-03-30T00:52:51.304Z|2006-10-27T15:25:57.884Z|00-7303-1410|https://randomuser.me/api/portraits/med/men/25.jpg  |
|NULL|Aada      |Korpi    |female|6795 Aleksanterinkatu, Inari, Pijt-Hme, Finland              |30722    |aada.korpi@example.com   |ticklishbutterfly985|1992-01-23T02:27:51.094Z|2007-05-28T01:02:11.364Z|07-054-246  |https://randomuser.me/api/portraits/med/women/41.jpg|
|NULL|Mahika    |Shetty   |female|2557 Rajpur Rd, Phusro, Meghalaya, India                        |51808    |mahika.shetty@example.com|tinyleopard903      |1998-06-24T06:06:21.019Z|2004-08-10T13:53:30.086Z|7846628802  |https://randomuser.me/api/portraits/med/women/37.jpg|
|NULL|Aapo      |Mikkola  |male  |9731 Korkeavuorenkatu, Pornainen, Southern Ostrobothnia, Finland|61016    |aapo.mikkola@example.com |happybutterfly242   |1991-09-20T18:34:34.043Z|2010-06-18T10:15:09.561Z|03-814-429  |https://randomuser.me/api/portraits/med/men/84.jpg  |
+----+----------+---------+------+----------------------------------------------------------------+---------+-------------------------+--------------------+------------------------+------------------------+------------+----------------------------------------------------+

24/09/13 02:43:56 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:43:56 INFO DAGScheduler: Got job 29 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:43:56 INFO DAGScheduler: Final stage: ResultStage 29 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:43:56 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:43:56 INFO DAGScheduler: Missing parents: List()
24/09/13 02:43:56 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[116] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:43:56 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 45.7 KiB, free 434.2 MiB)
24/09/13 02:43:56 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
24/09/13 02:43:56 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:43:56 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1585
24/09/13 02:43:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[116] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:43:56 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
24/09/13 02:43:56 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:43:56 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:43:56 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 528 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:43:56 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
24/09/13 02:43:56 INFO DAGScheduler: ResultStage 29 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.533 s
24/09/13 02:43:56 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:43:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
24/09/13 02:43:56 INFO DAGScheduler: Job 29 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.534715 s
2024-09-13 02:43:56,772 - INFO - Inserting data: {'id': None, 'first_name': 'Noah', 'last_name': 'Graham', 'gender': 'male', 'address': '4125 Camden Ave, Dubbo, New South Wales, Australia', 'post_code': '7398', 'email': 'noah.graham@example.com', 'username': 'silverzebra813', 'dob': '1990-03-30T00:52:51.304Z', 'registered_date': '2006-10-27T15:25:57.884Z', 'phone': '00-7303-1410', 'picture': 'https://randomuser.me/api/portraits/med/men/25.jpg'}
2024-09-13 02:43:56,776 - INFO - Data inserted for Noah Graham with ID e069add2-1d7e-479f-a034-97f4526be668
2024-09-13 02:43:56,776 - INFO - Successfully inserted data for Noah Graham
2024-09-13 02:43:56,776 - INFO - Inserting data: {'id': None, 'first_name': 'Aada', 'last_name': 'Korpi', 'gender': 'female', 'address': '6795 Aleksanterinkatu, Inari, Pijt-Hme, Finland', 'post_code': '30722', 'email': 'aada.korpi@example.com', 'username': 'ticklishbutterfly985', 'dob': '1992-01-23T02:27:51.094Z', 'registered_date': '2007-05-28T01:02:11.364Z', 'phone': '07-054-246', 'picture': 'https://randomuser.me/api/portraits/med/women/41.jpg'}
2024-09-13 02:43:56,781 - INFO - Data inserted for Aada Korpi with ID f8716fc2-2703-4b67-99f2-56269cb2a881
2024-09-13 02:43:56,781 - INFO - Successfully inserted data for Aada Korpi
2024-09-13 02:43:56,781 - INFO - Inserting data: {'id': None, 'first_name': 'Mahika', 'last_name': 'Shetty', 'gender': 'female', 'address': '2557 Rajpur Rd, Phusro, Meghalaya, India', 'post_code': '51808', 'email': 'mahika.shetty@example.com', 'username': 'tinyleopard903', 'dob': '1998-06-24T06:06:21.019Z', 'registered_date': '2004-08-10T13:53:30.086Z', 'phone': '7846628802', 'picture': 'https://randomuser.me/api/portraits/med/women/37.jpg'}
2024-09-13 02:43:56,784 - INFO - Data inserted for Mahika Shetty with ID 5b4333e6-ce94-4cd2-b746-414afb88fa42
2024-09-13 02:43:56,784 - INFO - Successfully inserted data for Mahika Shetty
2024-09-13 02:43:56,784 - INFO - Inserting data: {'id': None, 'first_name': 'Aapo', 'last_name': 'Mikkola', 'gender': 'male', 'address': '9731 Korkeavuorenkatu, Pornainen, Southern Ostrobothnia, Finland', 'post_code': '61016', 'email': 'aapo.mikkola@example.com', 'username': 'happybutterfly242', 'dob': '1991-09-20T18:34:34.043Z', 'registered_date': '2010-06-18T10:15:09.561Z', 'phone': '03-814-429', 'picture': 'https://randomuser.me/api/portraits/med/men/84.jpg'}
2024-09-13 02:43:56,788 - INFO - Data inserted for Aapo Mikkola with ID bd841799-7a58-438a-a33d-83288a69889c
2024-09-13 02:43:56,788 - INFO - Successfully inserted data for Aapo Mikkola
2024-09-13 02:43:56,788 - INFO - Finished processing batch 10
24/09/13 02:43:56 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/10 using temp file file:/tmp/checkpoint/commits/.10.ce44c073-f855-48f7-b2b8-23c1143889d1.tmp
24/09/13 02:43:56 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.10.ce44c073-f855-48f7-b2b8-23c1143889d1.tmp to file:/tmp/checkpoint/commits/10
24/09/13 02:43:56 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:43:55.001Z",
  "batchId" : 10,
  "numInputRows" : 9,
  "inputRowsPerSecond" : 1.8018018018018018,
  "processedRowsPerSecond" : 4.994450610432852,
  "durationMs" : {
    "addBatch" : 1740,
    "commitOffsets" : 13,
    "getBatch" : 0,
    "latestOffset" : 9,
    "queryPlanning" : 9,
    "triggerExecution" : 1802,
    "walCommit" : 29
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 25
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 29
      }
    },
    "latestOffset" : null,
    "numInputRows" : 9,
    "inputRowsPerSecond" : 1.8018018018018018,
    "processedRowsPerSecond" : 4.994450610432852
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/11 using temp file file:/tmp/checkpoint/offsets/.11.054a4731-37a3-465b-89cd-26d1a4e9f978.tmp
24/09/13 02:44:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.11.054a4731-37a3-465b-89cd-26d1a4e9f978.tmp to file:/tmp/checkpoint/offsets/11
24/09/13 02:44:00 INFO MicroBatchExecution: Committed offsets for batch 11. Metadata OffsetSeqMetadata(0,1726195440009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:00,056 - INFO - Received command c on object id p0
24/09/13 02:44:00 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:44:00 INFO DAGScheduler: Got job 30 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:00 INFO DAGScheduler: Final stage: ResultStage 30 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:00 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:00 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:00 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[123] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:00 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 42.8 KiB, free 434.1 MiB)
24/09/13 02:44:00 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.1 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:00 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[123] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:00 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
24/09/13 02:44:00 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 275 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:00 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
24/09/13 02:44:00 INFO DAGScheduler: ResultStage 30 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.286 s
24/09/13 02:44:00 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
24/09/13 02:44:00 INFO DAGScheduler: Job 30 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.287388 s
2024-09-13 02:44:00,355 - INFO - Processing batch 11
2024-09-13 02:44:00,355 - INFO - Batch content:
24/09/13 02:44:00 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:44:00 INFO DAGScheduler: Got job 31 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:00 INFO DAGScheduler: Final stage: ResultStage 31 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:00 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:00 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:00 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[125] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:00 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 46.6 KiB, free 434.3 MiB)
24/09/13 02:44:00 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.3 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[125] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:00 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
24/09/13 02:44:00 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:00 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 533 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:00 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
24/09/13 02:44:00 INFO DAGScheduler: ResultStage 31 (showString at NativeMethodAccessorImpl.java:0) finished in 0.538 s
24/09/13 02:44:00 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
24/09/13 02:44:00 INFO DAGScheduler: Job 31 finished: showString at NativeMethodAccessorImpl.java:0, took 0.540731 s
+----+----------+----------+------+--------------------------------------------------------+---------+----------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name |gender|address                                                 |post_code|email                       |username     |dob                     |registered_date         |phone         |picture                                             |
+----+----------+----------+------+--------------------------------------------------------+---------+----------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Natalie   |Baker     |female|8034 Pecan Acres Ln, Charlotte, Minnesota, United States|85036    |natalie.baker@example.com   |blacklion166 |1992-07-20T22:16:53.712Z|2003-06-03T17:20:27.734Z|(646) 690-9669|https://randomuser.me/api/portraits/med/women/88.jpg|
|NULL|Meral     |Poyrazolu|female|3031 Filistin Cd, Kastamonu, Zonguldak, Turkey          |93623    |meral.poyrazoglu@example.com|greenmouse622|1956-07-22T05:30:20.144Z|2006-06-26T19:16:32.174Z|(231)-198-3211|https://randomuser.me/api/portraits/med/women/45.jpg|
+----+----------+----------+------+--------------------------------------------------------+---------+----------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:44:00 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:00 INFO DAGScheduler: Got job 32 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:00 INFO DAGScheduler: Final stage: ResultStage 32 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:00 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:00 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:00 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[127] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:00 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 45.7 KiB, free 434.2 MiB)
24/09/13 02:44:00 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
24/09/13 02:44:00 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:00 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[127] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:00 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
24/09/13 02:44:00 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:00 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:01 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 535 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:01 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
24/09/13 02:44:01 INFO DAGScheduler: ResultStage 32 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.540 s
24/09/13 02:44:01 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
24/09/13 02:44:01 INFO DAGScheduler: Job 32 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.541557 s
2024-09-13 02:44:01,478 - INFO - Inserting data: {'id': None, 'first_name': 'Natalie', 'last_name': 'Baker', 'gender': 'female', 'address': '8034 Pecan Acres Ln, Charlotte, Minnesota, United States', 'post_code': '85036', 'email': 'natalie.baker@example.com', 'username': 'blacklion166', 'dob': '1992-07-20T22:16:53.712Z', 'registered_date': '2003-06-03T17:20:27.734Z', 'phone': '(646) 690-9669', 'picture': 'https://randomuser.me/api/portraits/med/women/88.jpg'}
2024-09-13 02:44:01,481 - INFO - Data inserted for Natalie Baker with ID 62401f0a-a7e1-4127-93d8-0ca4f49d21e9
2024-09-13 02:44:01,481 - INFO - Successfully inserted data for Natalie Baker
2024-09-13 02:44:01,481 - INFO - Inserting data: {'id': None, 'first_name': 'Meral', 'last_name': 'Poyrazolu', 'gender': 'female', 'address': '3031 Filistin Cd, Kastamonu, Zonguldak, Turkey', 'post_code': '93623', 'email': 'meral.poyrazoglu@example.com', 'username': 'greenmouse622', 'dob': '1956-07-22T05:30:20.144Z', 'registered_date': '2006-06-26T19:16:32.174Z', 'phone': '(231)-198-3211', 'picture': 'https://randomuser.me/api/portraits/med/women/45.jpg'}
2024-09-13 02:44:01,484 - INFO - Data inserted for Meral Poyrazolu with ID 9abe8edc-3f8d-4b3a-b7e5-42d1908a5ee8
2024-09-13 02:44:01,484 - INFO - Successfully inserted data for Meral Poyrazolu
2024-09-13 02:44:01,484 - INFO - Finished processing batch 11
24/09/13 02:44:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/11 using temp file file:/tmp/checkpoint/commits/.11.2cd2d08c-2aac-4c07-81b0-ab2523155386.tmp
24/09/13 02:44:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.11.2cd2d08c-2aac-4c07-81b0-ab2523155386.tmp to file:/tmp/checkpoint/commits/11
24/09/13 02:44:01 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:00.000Z",
  "batchId" : 11,
  "numInputRows" : 5,
  "inputRowsPerSecond" : 1.0002000400080016,
  "processedRowsPerSecond" : 3.33555703802535,
  "durationMs" : {
    "addBatch" : 1444,
    "commitOffsets" : 14,
    "getBatch" : 0,
    "latestOffset" : 8,
    "queryPlanning" : 10,
    "triggerExecution" : 1498,
    "walCommit" : 20
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 29
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 31
      }
    },
    "latestOffset" : null,
    "numInputRows" : 5,
    "inputRowsPerSecond" : 1.0002000400080016,
    "processedRowsPerSecond" : 3.33555703802535
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/12 using temp file file:/tmp/checkpoint/offsets/.12.6a063ebd-78e0-40e3-8792-d19e8c893096.tmp
24/09/13 02:44:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.12.6a063ebd-78e0-40e3-8792-d19e8c893096.tmp to file:/tmp/checkpoint/offsets/12
24/09/13 02:44:05 INFO MicroBatchExecution: Committed offsets for batch 12. Metadata OffsetSeqMetadata(0,1726195445008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:05,055 - INFO - Received command c on object id p0
24/09/13 02:44:05 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:44:05 INFO DAGScheduler: Got job 33 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:05 INFO DAGScheduler: Final stage: ResultStage 33 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:05 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:05 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:05 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[134] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:05 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:44:05 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:44:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:05 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[134] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:05 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
24/09/13 02:44:05 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:05 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 27 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:05 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
24/09/13 02:44:05 INFO DAGScheduler: ResultStage 33 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.030 s
24/09/13 02:44:05 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished
24/09/13 02:44:05 INFO DAGScheduler: Job 33 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.032253 s
2024-09-13 02:44:05,098 - INFO - Processing batch 12
2024-09-13 02:44:05,098 - INFO - Batch content:
24/09/13 02:44:05 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:44:05 INFO DAGScheduler: Got job 34 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:05 INFO DAGScheduler: Final stage: ResultStage 34 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:05 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:05 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:05 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[136] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:05 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 46.6 KiB, free 434.1 MiB)
24/09/13 02:44:05 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.1 MiB)
24/09/13 02:44:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:05 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[136] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:05 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0
24/09/13 02:44:05 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:05 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 532 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:05 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
24/09/13 02:44:05 INFO DAGScheduler: ResultStage 34 (showString at NativeMethodAccessorImpl.java:0) finished in 0.537 s
24/09/13 02:44:05 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
24/09/13 02:44:05 INFO DAGScheduler: Job 34 finished: showString at NativeMethodAccessorImpl.java:0, took 0.538289 s
+----+----------+---------+------+--------------------------------------------------------+---------+--------------------------+---------------+------------------------+------------------------+------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                 |post_code|email                     |username       |dob                     |registered_date         |phone       |picture                                             |
+----+----------+---------+------+--------------------------------------------------------+---------+--------------------------+---------------+------------------------+------------------------+------------+----------------------------------------------------+
|NULL|Lenni     |Anttila  |male  |9098 Bulevardi, Hollola, Southern Savonia, Finland      |70302    |lenni.anttila@example.com |bigelephant698 |1965-01-17T08:02:33.889Z|2019-11-10T07:40:55.825Z|07-053-096  |https://randomuser.me/api/portraits/med/men/59.jpg  |
|NULL|Sanni     |Toivonen |female|4492 Esplanadi, Evijrvi, Northern Savonia, Finland     |34048    |sanni.toivonen@example.com|redswan337     |1991-07-06T17:01:27.321Z|2019-09-06T16:54:28.620Z|08-865-168  |https://randomuser.me/api/portraits/med/women/85.jpg|
|NULL|Kate      |Ross     |female|7449 Stanley Road, Coventry, Strathclyde, United Kingdom|H7 0JN   |kate.ross@example.com     |brownzebra997  |1960-09-02T06:48:29.838Z|2003-02-07T12:03:59.516Z|017684 50453|https://randomuser.me/api/portraits/med/women/10.jpg|
|NULL|     |    |female|4915  , ,  , Iran       |34871    |mhrs.mrdy@example.com     |smallladybug727|1988-03-26T10:13:25.706Z|2017-01-23T11:23:21.184Z|077-49421335|https://randomuser.me/api/portraits/med/women/48.jpg|
+----+----------+---------+------+--------------------------------------------------------+---------+--------------------------+---------------+------------------------+------------------------+------------+----------------------------------------------------+

24/09/13 02:44:05 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:05 INFO DAGScheduler: Got job 35 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:05 INFO DAGScheduler: Final stage: ResultStage 35 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:05 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:05 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:05 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[138] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:05 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 45.7 KiB, free 434.1 MiB)
24/09/13 02:44:05 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.0 MiB)
24/09/13 02:44:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:05 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[138] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:05 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
24/09/13 02:44:05 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:06 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 535 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:06 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
24/09/13 02:44:06 INFO DAGScheduler: ResultStage 35 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.539 s
24/09/13 02:44:06 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
24/09/13 02:44:06 INFO DAGScheduler: Job 35 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.541409 s
2024-09-13 02:44:06,218 - INFO - Inserting data: {'id': None, 'first_name': 'Lenni', 'last_name': 'Anttila', 'gender': 'male', 'address': '9098 Bulevardi, Hollola, Southern Savonia, Finland', 'post_code': '70302', 'email': 'lenni.anttila@example.com', 'username': 'bigelephant698', 'dob': '1965-01-17T08:02:33.889Z', 'registered_date': '2019-11-10T07:40:55.825Z', 'phone': '07-053-096', 'picture': 'https://randomuser.me/api/portraits/med/men/59.jpg'}
2024-09-13 02:44:06,222 - INFO - Data inserted for Lenni Anttila with ID c510d82b-15f7-4c9d-a3f2-2287eef2fb3d
2024-09-13 02:44:06,222 - INFO - Successfully inserted data for Lenni Anttila
2024-09-13 02:44:06,222 - INFO - Inserting data: {'id': None, 'first_name': 'Sanni', 'last_name': 'Toivonen', 'gender': 'female', 'address': '4492 Esplanadi, Evijrvi, Northern Savonia, Finland', 'post_code': '34048', 'email': 'sanni.toivonen@example.com', 'username': 'redswan337', 'dob': '1991-07-06T17:01:27.321Z', 'registered_date': '2019-09-06T16:54:28.620Z', 'phone': '08-865-168', 'picture': 'https://randomuser.me/api/portraits/med/women/85.jpg'}
2024-09-13 02:44:06,227 - INFO - Data inserted for Sanni Toivonen with ID d52c4f76-c26c-42e9-aae1-43f2c4edfdd8
2024-09-13 02:44:06,227 - INFO - Successfully inserted data for Sanni Toivonen
2024-09-13 02:44:06,227 - INFO - Inserting data: {'id': None, 'first_name': 'Kate', 'last_name': 'Ross', 'gender': 'female', 'address': '7449 Stanley Road, Coventry, Strathclyde, United Kingdom', 'post_code': 'H7 0JN', 'email': 'kate.ross@example.com', 'username': 'brownzebra997', 'dob': '1960-09-02T06:48:29.838Z', 'registered_date': '2003-02-07T12:03:59.516Z', 'phone': '017684 50453', 'picture': 'https://randomuser.me/api/portraits/med/women/10.jpg'}
2024-09-13 02:44:06,229 - INFO - Data inserted for Kate Ross with ID 1b09ed50-9db1-456d-b52a-d6201d3b5623
2024-09-13 02:44:06,229 - INFO - Successfully inserted data for Kate Ross
2024-09-13 02:44:06,229 - INFO - Inserting data: {'id': None, 'first_name': '', 'last_name': '', 'gender': 'female', 'address': '4915  , ,  , Iran', 'post_code': '34871', 'email': 'mhrs.mrdy@example.com', 'username': 'smallladybug727', 'dob': '1988-03-26T10:13:25.706Z', 'registered_date': '2017-01-23T11:23:21.184Z', 'phone': '077-49421335', 'picture': 'https://randomuser.me/api/portraits/med/women/48.jpg'}
2024-09-13 02:44:06,232 - INFO - Data inserted for   with ID 82748ff1-2c79-44c2-9026-2679d7083ff2
2024-09-13 02:44:06,232 - INFO - Successfully inserted data for  
2024-09-13 02:44:06,232 - INFO - Finished processing batch 12
24/09/13 02:44:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/12 using temp file file:/tmp/checkpoint/commits/.12.852dfbf3-8200-4f4f-a5fd-4cbfc99bc1c2.tmp
24/09/13 02:44:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.12.852dfbf3-8200-4f4f-a5fd-4cbfc99bc1c2.tmp to file:/tmp/checkpoint/commits/12
24/09/13 02:44:06 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:05.003Z",
  "batchId" : 12,
  "numInputRows" : 9,
  "inputRowsPerSecond" : 1.798920647611433,
  "processedRowsPerSecond" : 7.223113964686998,
  "durationMs" : {
    "addBatch" : 1196,
    "commitOffsets" : 16,
    "getBatch" : 0,
    "latestOffset" : 5,
    "queryPlanning" : 8,
    "triggerExecution" : 1246,
    "walCommit" : 19
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 31
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 35
      }
    },
    "latestOffset" : null,
    "numInputRows" : 9,
    "inputRowsPerSecond" : 1.798920647611433,
    "processedRowsPerSecond" : 7.223113964686998
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:10 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/13 using temp file file:/tmp/checkpoint/offsets/.13.9b509880-2305-472c-91e0-1137d0a8f2df.tmp
24/09/13 02:44:10 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.13.9b509880-2305-472c-91e0-1137d0a8f2df.tmp to file:/tmp/checkpoint/offsets/13
24/09/13 02:44:10 INFO MicroBatchExecution: Committed offsets for batch 13. Metadata OffsetSeqMetadata(0,1726195450032,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:10 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:10 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:10 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:10 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:10,089 - INFO - Received command c on object id p0
24/09/13 02:44:10 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:44:10 INFO DAGScheduler: Got job 36 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:10 INFO DAGScheduler: Final stage: ResultStage 36 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:10 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:10 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:10 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[145] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:10 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 42.8 KiB, free 434.0 MiB)
24/09/13 02:44:10 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.0 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[145] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:10 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
24/09/13 02:44:10 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:10 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 549 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:10 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
24/09/13 02:44:10 INFO DAGScheduler: ResultStage 36 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.553 s
24/09/13 02:44:10 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
24/09/13 02:44:10 INFO DAGScheduler: Job 36 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.555607 s
2024-09-13 02:44:10,660 - INFO - Processing batch 13
2024-09-13 02:44:10,660 - INFO - Batch content:
24/09/13 02:44:10 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:44:10 INFO DAGScheduler: Got job 37 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:10 INFO DAGScheduler: Final stage: ResultStage 37 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:10 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:10 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:10 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[147] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:10 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 46.6 KiB, free 433.9 MiB)
24/09/13 02:44:10 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 433.9 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[147] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:10 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:10 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 65 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:10 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
24/09/13 02:44:10 INFO DAGScheduler: ResultStage 37 (showString at NativeMethodAccessorImpl.java:0) finished in 0.077 s
24/09/13 02:44:10 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
24/09/13 02:44:10 INFO DAGScheduler: Job 37 finished: showString at NativeMethodAccessorImpl.java:0, took 0.079286 s
+----+----------+---------+------+---------------------------------------------------+---------+----------------------------+----------------+------------------------+------------------------+------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                            |post_code|email                       |username        |dob                     |registered_date         |phone       |picture                                             |
+----+----------+---------+------+---------------------------------------------------+---------+----------------------------+----------------+------------------------+------------------------+------------+----------------------------------------------------+
|NULL|ivojin   |Ristovi |male  |3237 ure Jakia, uprija, North Baka, Serbia    |80298    |zivojin.ristovic@example.com|sadzebra237     |1980-05-02T00:20:25.250Z|2006-09-11T01:26:39.473Z|011-4671-682|https://randomuser.me/api/portraits/med/men/94.jpg  |
|NULL|Gottlieb  |Bienert  |male  |7083 Ringstrae, Minden-Lbbecke, Hessen, Germany  |16170    |gottlieb.bienert@example.com|organicrabbit356|1958-01-17T13:06:25.409Z|2022-02-24T03:52:42.694Z|0717-1376918|https://randomuser.me/api/portraits/med/men/67.jpg  |
|NULL|Kate      |Vargas   |female|8927 Kingsway, Chichester, Cornwall, United Kingdom|V7 4BU   |kate.vargas@example.com     |blackduck430    |1953-07-19T02:21:47.343Z|2011-12-17T02:36:10.529Z|015242 88477|https://randomuser.me/api/portraits/med/women/44.jpg|
+----+----------+---------+------+---------------------------------------------------+---------+----------------------------+----------------+------------------------+------------------------+------------+----------------------------------------------------+

24/09/13 02:44:10 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:10 INFO DAGScheduler: Got job 38 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:10 INFO DAGScheduler: Final stage: ResultStage 38 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:10 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:10 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:10 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[149] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:10 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:44:10 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:44:10 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:10 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[149] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:10 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0
24/09/13 02:44:10 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:10 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:11 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 539 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:11 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
24/09/13 02:44:11 INFO DAGScheduler: ResultStage 38 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.541 s
24/09/13 02:44:11 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
24/09/13 02:44:11 INFO DAGScheduler: Job 38 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.543714 s
2024-09-13 02:44:11,332 - INFO - Inserting data: {'id': None, 'first_name': 'ivojin', 'last_name': 'Ristovi', 'gender': 'male', 'address': '3237 ure Jakia, uprija, North Baka, Serbia', 'post_code': '80298', 'email': 'zivojin.ristovic@example.com', 'username': 'sadzebra237', 'dob': '1980-05-02T00:20:25.250Z', 'registered_date': '2006-09-11T01:26:39.473Z', 'phone': '011-4671-682', 'picture': 'https://randomuser.me/api/portraits/med/men/94.jpg'}
2024-09-13 02:44:11,339 - INFO - Data inserted for ivojin Ristovi with ID e4f40592-8d8d-4155-8ca6-8417fdfbb356
2024-09-13 02:44:11,339 - INFO - Successfully inserted data for ivojin Ristovi
2024-09-13 02:44:11,339 - INFO - Inserting data: {'id': None, 'first_name': 'Gottlieb', 'last_name': 'Bienert', 'gender': 'male', 'address': '7083 Ringstrae, Minden-Lbbecke, Hessen, Germany', 'post_code': '16170', 'email': 'gottlieb.bienert@example.com', 'username': 'organicrabbit356', 'dob': '1958-01-17T13:06:25.409Z', 'registered_date': '2022-02-24T03:52:42.694Z', 'phone': '0717-1376918', 'picture': 'https://randomuser.me/api/portraits/med/men/67.jpg'}
2024-09-13 02:44:11,343 - INFO - Data inserted for Gottlieb Bienert with ID 966c2fa8-e932-45b6-828e-c0648c212377
2024-09-13 02:44:11,344 - INFO - Successfully inserted data for Gottlieb Bienert
2024-09-13 02:44:11,344 - INFO - Inserting data: {'id': None, 'first_name': 'Kate', 'last_name': 'Vargas', 'gender': 'female', 'address': '8927 Kingsway, Chichester, Cornwall, United Kingdom', 'post_code': 'V7 4BU', 'email': 'kate.vargas@example.com', 'username': 'blackduck430', 'dob': '1953-07-19T02:21:47.343Z', 'registered_date': '2011-12-17T02:36:10.529Z', 'phone': '015242 88477', 'picture': 'https://randomuser.me/api/portraits/med/women/44.jpg'}
2024-09-13 02:44:11,347 - INFO - Data inserted for Kate Vargas with ID 27c89420-ac15-4c4b-8d17-534ca430a727
2024-09-13 02:44:11,347 - INFO - Successfully inserted data for Kate Vargas
2024-09-13 02:44:11,347 - INFO - Finished processing batch 13
24/09/13 02:44:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/13 using temp file file:/tmp/checkpoint/commits/.13.d6132067-d322-4db7-8144-b7d65fa8298f.tmp
24/09/13 02:44:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.13.d6132067-d322-4db7-8144-b7d65fa8298f.tmp to file:/tmp/checkpoint/commits/13
24/09/13 02:44:11 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:10.005Z",
  "batchId" : 13,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.399440223910436,
  "processedRowsPerSecond" : 5.090909090909091,
  "durationMs" : {
    "addBatch" : 1278,
    "commitOffsets" : 33,
    "getBatch" : 1,
    "latestOffset" : 8,
    "queryPlanning" : 15,
    "triggerExecution" : 1375,
    "walCommit" : 19
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 35
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 38
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.399440223910436,
    "processedRowsPerSecond" : 5.090909090909091
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:15 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/14 using temp file file:/tmp/checkpoint/offsets/.14.b8131202-0f18-4393-bf82-c7f1466dc3f4.tmp
24/09/13 02:44:15 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.14.b8131202-0f18-4393-bf82-c7f1466dc3f4.tmp to file:/tmp/checkpoint/offsets/14
24/09/13 02:44:15 INFO MicroBatchExecution: Committed offsets for batch 14. Metadata OffsetSeqMetadata(0,1726195455014,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:15 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:15,062 - INFO - Received command c on object id p0
24/09/13 02:44:15 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:44:15 INFO DAGScheduler: Got job 39 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:15 INFO DAGScheduler: Final stage: ResultStage 39 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:15 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:15 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:15 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[156] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:15 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:44:15 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:44:15 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:15 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[156] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:15 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
24/09/13 02:44:15 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:15 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:15 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 49 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:15 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
24/09/13 02:44:15 INFO DAGScheduler: ResultStage 39 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.053 s
24/09/13 02:44:15 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
24/09/13 02:44:15 INFO DAGScheduler: Job 39 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.053617 s
2024-09-13 02:44:15,127 - INFO - Processing batch 14
2024-09-13 02:44:15,127 - INFO - Batch content:
24/09/13 02:44:15 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:44:15 INFO DAGScheduler: Got job 40 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:15 INFO DAGScheduler: Final stage: ResultStage 40 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:15 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:15 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:15 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[158] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:15 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:44:15 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:44:15 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:15 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[158] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:15 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
24/09/13 02:44:15 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:15 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:15 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 543 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:15 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
24/09/13 02:44:15 INFO DAGScheduler: ResultStage 40 (showString at NativeMethodAccessorImpl.java:0) finished in 0.546 s
24/09/13 02:44:15 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
24/09/13 02:44:15 INFO DAGScheduler: Job 40 finished: showString at NativeMethodAccessorImpl.java:0, took 0.547336 s
+----+----------+-----------+------+--------------------------------------------------------------+---------+-----------------------------+---------------+------------------------+------------------------+--------------+--------------------------------------------------+
|id  |first_name|last_name  |gender|address                                                       |post_code|email                        |username       |dob                     |registered_date         |phone         |picture                                           |
+----+----------+-----------+------+--------------------------------------------------------------+---------+-----------------------------+---------------+------------------------+------------------------+--------------+--------------------------------------------------+
|NULL|Mikola    |Kozyar     |male  |1619 Geroyiv Sevastopolya, Privillya, Sumska, Ukraine         |34983    |mikola.kozyar@example.com    |greendog994    |1985-09-29T22:42:42.658Z|2015-08-11T17:58:39.371Z|(067) I35-0198|https://randomuser.me/api/portraits/med/men/66.jpg|
|NULL|Rinze     |Brugge     |male  |1171 Cornelis Anthoniszstraat, Hemrik, Overijssel, Netherlands|8049 WO  |rinze.brugge@example.com     |goldenpanda790 |1987-11-25T12:29:24.897Z|2011-05-22T03:52:59.776Z|(0549) 339088 |https://randomuser.me/api/portraits/med/men/73.jpg|
|NULL|Milan     |Veligorskiy|male  |8342 Obuhivskiy provulok, Pavlograd, Donecka, Ukraine         |45974    |milan.veligorskiy@example.com|ticklishbear508|1979-09-14T10:51:31.229Z|2006-01-24T16:56:44.308Z|(097) R55-2032|https://randomuser.me/api/portraits/med/men/29.jpg|
+----+----------+-----------+------+--------------------------------------------------------------+---------+-----------------------------+---------------+------------------------+------------------------+--------------+--------------------------------------------------+

24/09/13 02:44:15 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:15 INFO DAGScheduler: Got job 41 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:15 INFO DAGScheduler: Final stage: ResultStage 41 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:15 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:15 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:15 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[160] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:15 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 45.7 KiB, free 434.1 MiB)
24/09/13 02:44:15 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.1 MiB)
24/09/13 02:44:15 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:15 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[160] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:15 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
24/09/13 02:44:15 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:15 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:16 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 526 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:16 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
24/09/13 02:44:16 INFO DAGScheduler: ResultStage 41 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.529 s
24/09/13 02:44:16 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
24/09/13 02:44:16 INFO DAGScheduler: Job 41 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.531418 s
2024-09-13 02:44:16,238 - INFO - Inserting data: {'id': None, 'first_name': 'Mikola', 'last_name': 'Kozyar', 'gender': 'male', 'address': '1619 Geroyiv Sevastopolya, Privillya, Sumska, Ukraine', 'post_code': '34983', 'email': 'mikola.kozyar@example.com', 'username': 'greendog994', 'dob': '1985-09-29T22:42:42.658Z', 'registered_date': '2015-08-11T17:58:39.371Z', 'phone': '(067) I35-0198', 'picture': 'https://randomuser.me/api/portraits/med/men/66.jpg'}
2024-09-13 02:44:16,241 - INFO - Data inserted for Mikola Kozyar with ID 867b4c74-100d-450a-8d49-52a7404365c5
2024-09-13 02:44:16,241 - INFO - Successfully inserted data for Mikola Kozyar
2024-09-13 02:44:16,241 - INFO - Inserting data: {'id': None, 'first_name': 'Rinze', 'last_name': 'Brugge', 'gender': 'male', 'address': '1171 Cornelis Anthoniszstraat, Hemrik, Overijssel, Netherlands', 'post_code': '8049 WO', 'email': 'rinze.brugge@example.com', 'username': 'goldenpanda790', 'dob': '1987-11-25T12:29:24.897Z', 'registered_date': '2011-05-22T03:52:59.776Z', 'phone': '(0549) 339088', 'picture': 'https://randomuser.me/api/portraits/med/men/73.jpg'}
2024-09-13 02:44:16,246 - INFO - Data inserted for Rinze Brugge with ID a938c058-13d5-4b1d-885d-220184d6f23a
2024-09-13 02:44:16,246 - INFO - Successfully inserted data for Rinze Brugge
2024-09-13 02:44:16,246 - INFO - Inserting data: {'id': None, 'first_name': 'Milan', 'last_name': 'Veligorskiy', 'gender': 'male', 'address': '8342 Obuhivskiy provulok, Pavlograd, Donecka, Ukraine', 'post_code': '45974', 'email': 'milan.veligorskiy@example.com', 'username': 'ticklishbear508', 'dob': '1979-09-14T10:51:31.229Z', 'registered_date': '2006-01-24T16:56:44.308Z', 'phone': '(097) R55-2032', 'picture': 'https://randomuser.me/api/portraits/med/men/29.jpg'}
2024-09-13 02:44:16,248 - INFO - Data inserted for Milan Veligorskiy with ID 3ee48a64-5322-4ddc-beba-5efb94b02562
2024-09-13 02:44:16,249 - INFO - Successfully inserted data for Milan Veligorskiy
2024-09-13 02:44:16,249 - INFO - Finished processing batch 14
24/09/13 02:44:16 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/14 using temp file file:/tmp/checkpoint/commits/.14.b2d9255f-992d-43d4-9ecb-e6f34ea698d5.tmp
24/09/13 02:44:16 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.14.b2d9255f-992d-43d4-9ecb-e6f34ea698d5.tmp to file:/tmp/checkpoint/commits/14
24/09/13 02:44:16 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:15.005Z",
  "batchId" : 14,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4,
  "processedRowsPerSecond" : 5.54675118858954,
  "durationMs" : {
    "addBatch" : 1203,
    "commitOffsets" : 18,
    "getBatch" : 0,
    "latestOffset" : 8,
    "queryPlanning" : 10,
    "triggerExecution" : 1262,
    "walCommit" : 21
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 38
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 41
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4,
    "processedRowsPerSecond" : 5.54675118858954
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/15 using temp file file:/tmp/checkpoint/offsets/.15.e05b41fa-b650-4bd0-8859-0737dbd20f11.tmp
24/09/13 02:44:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.15.e05b41fa-b650-4bd0-8859-0737dbd20f11.tmp to file:/tmp/checkpoint/offsets/15
24/09/13 02:44:20 INFO MicroBatchExecution: Committed offsets for batch 15. Metadata OffsetSeqMetadata(0,1726195460033,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:20 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:20,084 - INFO - Received command c on object id p0
24/09/13 02:44:20 INFO SparkContext: Starting job: isEmpty at NativeMethodAccessorImpl.java:0
24/09/13 02:44:20 INFO DAGScheduler: Got job 42 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:20 INFO DAGScheduler: Final stage: ResultStage 42 (isEmpty at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:20 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:20 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:20 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[167] at isEmpty at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:20 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 42.8 KiB, free 434.1 MiB)
24/09/13 02:44:20 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.0 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[167] at isEmpty at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:20 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
24/09/13 02:44:20 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:20 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 15 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:20 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
24/09/13 02:44:20 INFO DAGScheduler: ResultStage 42 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.020 s
24/09/13 02:44:20 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
24/09/13 02:44:20 INFO DAGScheduler: Job 42 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.020868 s
2024-09-13 02:44:20,114 - INFO - Processing batch 15
2024-09-13 02:44:20,114 - INFO - Batch content:
24/09/13 02:44:20 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:44:20 INFO DAGScheduler: Got job 43 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:20 INFO DAGScheduler: Final stage: ResultStage 43 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:20 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:20 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:20 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[169] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:20 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 46.6 KiB, free 434.0 MiB)
24/09/13 02:44:20 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.0 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[169] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:20 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 43) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 43) in 548 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:20 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
24/09/13 02:44:20 INFO DAGScheduler: ResultStage 43 (showString at NativeMethodAccessorImpl.java:0) finished in 0.558 s
24/09/13 02:44:20 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
24/09/13 02:44:20 INFO DAGScheduler: Job 43 finished: showString at NativeMethodAccessorImpl.java:0, took 0.559586 s
+----+----------+---------+------+---------------------------------------------------------+---------+---------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                  |post_code|email                      |username     |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+---------------------------------------------------------+---------+---------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Gwenda    |Planting |female|4492 Bergenshuizenseweg, Kolderveen, Limburg, Netherlands|7946 LT  |gwenda.planting@example.com|whitewolf512 |1998-12-07T10:56:27.745Z|2010-04-22T09:16:40.534Z|(0131) 934665 |https://randomuser.me/api/portraits/med/women/42.jpg|
|NULL|Koray     |Mertolu |male  |7634 Maka Cd, Aksaray, ankr, Turkey                  |93421    |koray.mertoglu@example.com |bluecat674   |1983-03-21T19:47:23.747Z|2018-01-30T02:44:10.917Z|(267)-596-8955|https://randomuser.me/api/portraits/med/men/63.jpg  |
|NULL|Elli      |Manninen |female|678 Tahmelantie, Humppila, Satakunta, Finland            |57377    |elli.manninen@example.com  |orangelion563|1971-05-06T16:13:04.242Z|2012-09-26T08:56:47.923Z|05-074-000    |https://randomuser.me/api/portraits/med/women/77.jpg|
|NULL|Cristine  |Melo     |female|5940 Rua Principal, Campo Grande, Amazonas, Brazil       |24171    |cristine.melo@example.com  |browntiger224|1948-08-24T00:53:06.084Z|2017-07-13T20:57:15.277Z|(11) 3027-6134|https://randomuser.me/api/portraits/med/women/27.jpg|
+----+----------+---------+------+---------------------------------------------------------+---------+---------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:44:20 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:20 INFO DAGScheduler: Got job 44 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:20 INFO DAGScheduler: Final stage: ResultStage 44 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:20 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:20 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:20 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[171] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:20 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:44:20 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:44:20 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[171] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:20 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
24/09/13 02:44:20 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:20 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:20 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 162 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:20 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
24/09/13 02:44:20 INFO DAGScheduler: ResultStage 44 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.165 s
24/09/13 02:44:20 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
24/09/13 02:44:20 INFO DAGScheduler: Job 44 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.168023 s
2024-09-13 02:44:20,876 - INFO - Inserting data: {'id': None, 'first_name': 'Gwenda', 'last_name': 'Planting', 'gender': 'female', 'address': '4492 Bergenshuizenseweg, Kolderveen, Limburg, Netherlands', 'post_code': '7946 LT', 'email': 'gwenda.planting@example.com', 'username': 'whitewolf512', 'dob': '1998-12-07T10:56:27.745Z', 'registered_date': '2010-04-22T09:16:40.534Z', 'phone': '(0131) 934665', 'picture': 'https://randomuser.me/api/portraits/med/women/42.jpg'}
2024-09-13 02:44:20,878 - INFO - Data inserted for Gwenda Planting with ID 3d8ecd93-a0de-422c-ae77-e50d0a263f71
2024-09-13 02:44:20,879 - INFO - Successfully inserted data for Gwenda Planting
2024-09-13 02:44:20,879 - INFO - Inserting data: {'id': None, 'first_name': 'Koray', 'last_name': 'Mertolu', 'gender': 'male', 'address': '7634 Maka Cd, Aksaray, ankr, Turkey', 'post_code': '93421', 'email': 'koray.mertoglu@example.com', 'username': 'bluecat674', 'dob': '1983-03-21T19:47:23.747Z', 'registered_date': '2018-01-30T02:44:10.917Z', 'phone': '(267)-596-8955', 'picture': 'https://randomuser.me/api/portraits/med/men/63.jpg'}
2024-09-13 02:44:20,881 - INFO - Data inserted for Koray Mertolu with ID 16cae541-b968-4625-920e-b5b222f5334c
2024-09-13 02:44:20,881 - INFO - Successfully inserted data for Koray Mertolu
2024-09-13 02:44:20,881 - INFO - Inserting data: {'id': None, 'first_name': 'Elli', 'last_name': 'Manninen', 'gender': 'female', 'address': '678 Tahmelantie, Humppila, Satakunta, Finland', 'post_code': '57377', 'email': 'elli.manninen@example.com', 'username': 'orangelion563', 'dob': '1971-05-06T16:13:04.242Z', 'registered_date': '2012-09-26T08:56:47.923Z', 'phone': '05-074-000', 'picture': 'https://randomuser.me/api/portraits/med/women/77.jpg'}
2024-09-13 02:44:20,884 - INFO - Data inserted for Elli Manninen with ID 4220d5cc-c760-41a7-afb1-55da79378a27
2024-09-13 02:44:20,884 - INFO - Successfully inserted data for Elli Manninen
2024-09-13 02:44:20,884 - INFO - Inserting data: {'id': None, 'first_name': 'Cristine', 'last_name': 'Melo', 'gender': 'female', 'address': '5940 Rua Principal, Campo Grande, Amazonas, Brazil', 'post_code': '24171', 'email': 'cristine.melo@example.com', 'username': 'browntiger224', 'dob': '1948-08-24T00:53:06.084Z', 'registered_date': '2017-07-13T20:57:15.277Z', 'phone': '(11) 3027-6134', 'picture': 'https://randomuser.me/api/portraits/med/women/27.jpg'}
2024-09-13 02:44:20,887 - INFO - Data inserted for Cristine Melo with ID f75b3674-9260-4ab9-9ffc-57e9b62c284f
2024-09-13 02:44:20,887 - INFO - Successfully inserted data for Cristine Melo
2024-09-13 02:44:20,887 - INFO - Finished processing batch 15
24/09/13 02:44:20 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/15 using temp file file:/tmp/checkpoint/commits/.15.64055ec0-3adc-477b-8c0c-86a236ed4a2a.tmp
24/09/13 02:44:20 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.15.64055ec0-3adc-477b-8c0c-86a236ed4a2a.tmp to file:/tmp/checkpoint/commits/15
24/09/13 02:44:20 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:20.003Z",
  "batchId" : 15,
  "numInputRows" : 9,
  "inputRowsPerSecond" : 1.800720288115246,
  "processedRowsPerSecond" : 10.022271714922049,
  "durationMs" : {
    "addBatch" : 816,
    "commitOffsets" : 13,
    "getBatch" : 0,
    "latestOffset" : 29,
    "queryPlanning" : 8,
    "triggerExecution" : 898,
    "walCommit" : 31
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 41
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 45
      }
    },
    "latestOffset" : null,
    "numInputRows" : 9,
    "inputRowsPerSecond" : 1.800720288115246,
    "processedRowsPerSecond" : 10.022271714922049
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/16 using temp file file:/tmp/checkpoint/offsets/.16.993b9961-448e-4505-9e6e-26e193ae1f5c.tmp
24/09/13 02:44:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.16.993b9961-448e-4505-9e6e-26e193ae1f5c.tmp to file:/tmp/checkpoint/offsets/16
24/09/13 02:44:25 INFO MicroBatchExecution: Committed offsets for batch 16. Metadata OffsetSeqMetadata(0,1726195465017,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:25 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:25,063 - INFO - Received command c on object id p0
24/09/13 02:44:25 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:44:25 INFO DAGScheduler: Got job 45 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:44:25 INFO DAGScheduler: Final stage: ResultStage 45 (isEmpty at <unknown>:0)
24/09/13 02:44:25 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:25 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:25 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[178] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:44:25 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:44:25 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:44:25 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:25 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[178] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:25 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
24/09/13 02:44:25 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:25 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:25 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 18 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:25 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
24/09/13 02:44:25 INFO DAGScheduler: ResultStage 45 (isEmpty at <unknown>:0) finished in 0.022 s
24/09/13 02:44:25 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
24/09/13 02:44:25 INFO DAGScheduler: Job 45 finished: isEmpty at <unknown>:0, took 0.023483 s
2024-09-13 02:44:25,100 - INFO - Processing batch 16
2024-09-13 02:44:25,100 - INFO - Batch content:
24/09/13 02:44:25 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/09/13 02:44:25 INFO DAGScheduler: Got job 46 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/09/13 02:44:25 INFO DAGScheduler: Final stage: ResultStage 46 (showString at NativeMethodAccessorImpl.java:0)
24/09/13 02:44:25 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:25 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:25 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[180] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/09/13 02:44:25 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:44:25 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:44:25 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:25 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[180] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:25 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
24/09/13 02:44:25 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:25 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:25 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 142 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:25 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
24/09/13 02:44:25 INFO DAGScheduler: ResultStage 46 (showString at NativeMethodAccessorImpl.java:0) finished in 0.145 s
24/09/13 02:44:25 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
24/09/13 02:44:25 INFO DAGScheduler: Job 46 finished: showString at NativeMethodAccessorImpl.java:0, took 0.146628 s
+----+----------+---------+------+-----------------------------------------------------+---------+---------------------------+---------------+------------------------+------------------------+--------------+--------------------------------------------------+
|id  |first_name|last_name|gender|address                                              |post_code|email                      |username       |dob                     |registered_date         |phone         |picture                                           |
+----+----------+---------+------+-----------------------------------------------------+---------+---------------------------+---------------+------------------------+------------------------+--------------+--------------------------------------------------+
|NULL|Romuald   |Hengst   |male  |4948 Amselweg, Horstmar, Nordrhein-Westfalen, Germany|57711    |romuald.hengst@example.com |smallleopard410|1955-11-29T19:38:54.687Z|2006-01-22T15:40:40.306Z|0505-0766763  |https://randomuser.me/api/portraits/med/men/32.jpg|
|NULL|Radko     |Cegelskiy|male  |9137 Vinogradna, Berezan, Vinnicka, Ukraine          |83428    |radko.cegelskiy@example.com|sadsnake865    |1957-11-10T23:51:47.667Z|2003-06-15T09:20:55.166Z|(099) T73-4775|https://randomuser.me/api/portraits/med/men/22.jpg|
|NULL|Lance     |Williams |male  |3513 N Stelling Rd, Bowral, Queensland, Australia    |350      |lance.williams@example.com |bluecat951     |2000-05-28T18:43:02.795Z|2009-07-12T00:53:32.268Z|01-4761-2329  |https://randomuser.me/api/portraits/med/men/78.jpg|
+----+----------+---------+------+-----------------------------------------------------+---------+---------------------------+---------------+------------------------+------------------------+--------------+--------------------------------------------------+

24/09/13 02:44:25 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:25 INFO DAGScheduler: Got job 47 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:25 INFO DAGScheduler: Final stage: ResultStage 47 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:25 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:25 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:25 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[182] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:25 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 45.7 KiB, free 434.1 MiB)
24/09/13 02:44:25 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.1 MiB)
24/09/13 02:44:25 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:25 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[182] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:25 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
24/09/13 02:44:25 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:25 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:25 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 534 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:25 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
24/09/13 02:44:25 INFO DAGScheduler: ResultStage 47 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.538 s
24/09/13 02:44:25 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
24/09/13 02:44:25 INFO DAGScheduler: Job 47 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.539763 s
2024-09-13 02:44:25,818 - INFO - Inserting data: {'id': None, 'first_name': 'Romuald', 'last_name': 'Hengst', 'gender': 'male', 'address': '4948 Amselweg, Horstmar, Nordrhein-Westfalen, Germany', 'post_code': '57711', 'email': 'romuald.hengst@example.com', 'username': 'smallleopard410', 'dob': '1955-11-29T19:38:54.687Z', 'registered_date': '2006-01-22T15:40:40.306Z', 'phone': '0505-0766763', 'picture': 'https://randomuser.me/api/portraits/med/men/32.jpg'}
2024-09-13 02:44:25,821 - INFO - Data inserted for Romuald Hengst with ID ff42fe8f-efe2-4367-8483-aa9edfa0ad19
2024-09-13 02:44:25,821 - INFO - Successfully inserted data for Romuald Hengst
2024-09-13 02:44:25,821 - INFO - Inserting data: {'id': None, 'first_name': 'Radko', 'last_name': 'Cegelskiy', 'gender': 'male', 'address': '9137 Vinogradna, Berezan, Vinnicka, Ukraine', 'post_code': '83428', 'email': 'radko.cegelskiy@example.com', 'username': 'sadsnake865', 'dob': '1957-11-10T23:51:47.667Z', 'registered_date': '2003-06-15T09:20:55.166Z', 'phone': '(099) T73-4775', 'picture': 'https://randomuser.me/api/portraits/med/men/22.jpg'}
2024-09-13 02:44:25,826 - INFO - Data inserted for Radko Cegelskiy with ID f66f6354-0a3f-4a8f-9160-9a19163bb0dc
2024-09-13 02:44:25,826 - INFO - Successfully inserted data for Radko Cegelskiy
2024-09-13 02:44:25,826 - INFO - Inserting data: {'id': None, 'first_name': 'Lance', 'last_name': 'Williams', 'gender': 'male', 'address': '3513 N Stelling Rd, Bowral, Queensland, Australia', 'post_code': '350', 'email': 'lance.williams@example.com', 'username': 'bluecat951', 'dob': '2000-05-28T18:43:02.795Z', 'registered_date': '2009-07-12T00:53:32.268Z', 'phone': '01-4761-2329', 'picture': 'https://randomuser.me/api/portraits/med/men/78.jpg'}
2024-09-13 02:44:25,829 - INFO - Data inserted for Lance Williams with ID e9ed77bd-5ce3-45d7-aea9-27aed367559f
2024-09-13 02:44:25,829 - INFO - Successfully inserted data for Lance Williams
2024-09-13 02:44:25,829 - INFO - Finished processing batch 16
24/09/13 02:44:25 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/16 using temp file file:/tmp/checkpoint/commits/.16.a7f2f954-459b-4968-9ef3-b4803783ff65.tmp
24/09/13 02:44:25 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.16.a7f2f954-459b-4968-9ef3-b4803783ff65.tmp to file:/tmp/checkpoint/commits/16
24/09/13 02:44:25 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:25.001Z",
  "batchId" : 16,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4005602240896358,
  "processedRowsPerSecond" : 8.284023668639053,
  "durationMs" : {
    "addBatch" : 779,
    "commitOffsets" : 16,
    "getBatch" : 0,
    "latestOffset" : 15,
    "queryPlanning" : 9,
    "triggerExecution" : 844,
    "walCommit" : 22
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 45
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 48
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4005602240896358,
    "processedRowsPerSecond" : 8.284023668639053
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:30 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/17 using temp file file:/tmp/checkpoint/offsets/.17.89ebe632-5889-4f07-9d7c-7935bf8a340f.tmp
24/09/13 02:44:30 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.17.89ebe632-5889-4f07-9d7c-7935bf8a340f.tmp to file:/tmp/checkpoint/offsets/17
24/09/13 02:44:30 INFO MicroBatchExecution: Committed offsets for batch 17. Metadata OffsetSeqMetadata(0,1726195470008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:30 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:30,053 - INFO - Received command c on object id p0
24/09/13 02:44:30 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:44:30 INFO DAGScheduler: Got job 48 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:44:30 INFO DAGScheduler: Final stage: ResultStage 48 (isEmpty at <unknown>:0)
24/09/13 02:44:30 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:30 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:30 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[189] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:44:30 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 42.8 KiB, free 434.1 MiB)
24/09/13 02:44:30 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.0 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[189] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:30 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
24/09/13 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 48) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:30 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 48) in 538 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:30 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
24/09/13 02:44:30 INFO DAGScheduler: ResultStage 48 (isEmpty at <unknown>:0) finished in 0.542 s
24/09/13 02:44:30 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
24/09/13 02:44:30 INFO DAGScheduler: Job 48 finished: isEmpty at <unknown>:0, took 0.544260 s
2024-09-13 02:44:30,609 - INFO - Processing batch 17
2024-09-13 02:44:30,609 - INFO - Batch content:
24/09/13 02:44:30 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 02:44:30 INFO DAGScheduler: Got job 49 (showString at <unknown>:0) with 1 output partitions
24/09/13 02:44:30 INFO DAGScheduler: Final stage: ResultStage 49 (showString at <unknown>:0)
24/09/13 02:44:30 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:30 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:30 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[191] at showString at <unknown>:0), which has no missing parents
24/09/13 02:44:30 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 46.6 KiB, free 434.0 MiB)
24/09/13 02:44:30 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.0 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[191] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:30 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 49) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:30 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:31 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 49) in 540 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:31 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
24/09/13 02:44:31 INFO DAGScheduler: ResultStage 49 (showString at <unknown>:0) finished in 0.549 s
24/09/13 02:44:31 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
24/09/13 02:44:31 INFO DAGScheduler: Job 49 finished: showString at <unknown>:0, took 0.551014 s
+----+----------+----------+------+------------------------------------------------------------------------+---------+---------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name |gender|address                                                                 |post_code|email                      |username        |dob                     |registered_date         |phone         |picture                                             |
+----+----------+----------+------+------------------------------------------------------------------------+---------+---------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Flora     |Barbier   |female|403 Rue de L'Abb-Groult, Nantes, Oise, France                          |48114    |flora.barbier@example.com  |orangemeercat909|1952-05-23T01:51:12.700Z|2014-07-02T12:18:02.819Z|05-08-48-15-95|https://randomuser.me/api/portraits/med/women/69.jpg|
|NULL|Adrian    |Williams  |male  |3048 Westmoreland Street, Fermoy, Kerry, Ireland                        |81186    |adrian.williams@example.com|whitebear829    |1944-08-26T05:32:48.419Z|2002-11-20T15:38:03.075Z|031-055-0939  |https://randomuser.me/api/portraits/med/men/81.jpg  |
|NULL|Maya      |Fortin    |female|1356 Simcoe St, Notre Dame de Lourdes, Newfoundland and Labrador, Canada|X2G 0K5  |maya.fortin@example.com    |brownsnake834   |1965-12-12T05:06:18.695Z|2016-09-08T17:43:09.535Z|U77 N97-5289  |https://randomuser.me/api/portraits/med/women/7.jpg |
|NULL|Kaya      |Dalarolu|male  |315 Kushimoto Sk, Burdur, Adana, Turkey                                 |54924    |kaya.daglaroglu@example.com|purplecat743    |1960-09-30T01:53:26.657Z|2021-02-19T18:20:52.703Z|(709)-447-1937|https://randomuser.me/api/portraits/med/men/20.jpg  |
+----+----------+----------+------+------------------------------------------------------------------------+---------+---------------------------+----------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:44:31 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:31 INFO DAGScheduler: Got job 50 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:31 INFO DAGScheduler: Final stage: ResultStage 50 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:31 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:31 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:31 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[193] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:31 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:44:31 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:44:31 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:31 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[193] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:31 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
24/09/13 02:44:31 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 50) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:31 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:31 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 50) in 202 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:31 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
24/09/13 02:44:31 INFO DAGScheduler: ResultStage 50 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.205 s
24/09/13 02:44:31 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
24/09/13 02:44:31 INFO DAGScheduler: Job 50 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.207132 s
2024-09-13 02:44:31,408 - INFO - Inserting data: {'id': None, 'first_name': 'Flora', 'last_name': 'Barbier', 'gender': 'female', 'address': "403 Rue de L'Abb-Groult, Nantes, Oise, France", 'post_code': '48114', 'email': 'flora.barbier@example.com', 'username': 'orangemeercat909', 'dob': '1952-05-23T01:51:12.700Z', 'registered_date': '2014-07-02T12:18:02.819Z', 'phone': '05-08-48-15-95', 'picture': 'https://randomuser.me/api/portraits/med/women/69.jpg'}
2024-09-13 02:44:31,411 - INFO - Data inserted for Flora Barbier with ID 8ae4b80d-9ffa-4e78-a659-927d25dd8839
2024-09-13 02:44:31,411 - INFO - Successfully inserted data for Flora Barbier
2024-09-13 02:44:31,411 - INFO - Inserting data: {'id': None, 'first_name': 'Adrian', 'last_name': 'Williams', 'gender': 'male', 'address': '3048 Westmoreland Street, Fermoy, Kerry, Ireland', 'post_code': '81186', 'email': 'adrian.williams@example.com', 'username': 'whitebear829', 'dob': '1944-08-26T05:32:48.419Z', 'registered_date': '2002-11-20T15:38:03.075Z', 'phone': '031-055-0939', 'picture': 'https://randomuser.me/api/portraits/med/men/81.jpg'}
2024-09-13 02:44:31,413 - INFO - Data inserted for Adrian Williams with ID 6676342f-c1de-445a-965a-ea5cbf7188a6
2024-09-13 02:44:31,413 - INFO - Successfully inserted data for Adrian Williams
2024-09-13 02:44:31,413 - INFO - Inserting data: {'id': None, 'first_name': 'Maya', 'last_name': 'Fortin', 'gender': 'female', 'address': '1356 Simcoe St, Notre Dame de Lourdes, Newfoundland and Labrador, Canada', 'post_code': 'X2G 0K5', 'email': 'maya.fortin@example.com', 'username': 'brownsnake834', 'dob': '1965-12-12T05:06:18.695Z', 'registered_date': '2016-09-08T17:43:09.535Z', 'phone': 'U77 N97-5289', 'picture': 'https://randomuser.me/api/portraits/med/women/7.jpg'}
2024-09-13 02:44:31,416 - INFO - Data inserted for Maya Fortin with ID c273ed59-c024-4106-a6c1-6dfd519196b8
2024-09-13 02:44:31,416 - INFO - Successfully inserted data for Maya Fortin
2024-09-13 02:44:31,416 - INFO - Inserting data: {'id': None, 'first_name': 'Kaya', 'last_name': 'Dalarolu', 'gender': 'male', 'address': '315 Kushimoto Sk, Burdur, Adana, Turkey', 'post_code': '54924', 'email': 'kaya.daglaroglu@example.com', 'username': 'purplecat743', 'dob': '1960-09-30T01:53:26.657Z', 'registered_date': '2021-02-19T18:20:52.703Z', 'phone': '(709)-447-1937', 'picture': 'https://randomuser.me/api/portraits/med/men/20.jpg'}
2024-09-13 02:44:31,418 - INFO - Data inserted for Kaya Dalarolu with ID 2f182d69-7095-40c1-837e-b10a889f8d17
2024-09-13 02:44:31,418 - INFO - Successfully inserted data for Kaya Dalarolu
2024-09-13 02:44:31,418 - INFO - Finished processing batch 17
24/09/13 02:44:31 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/17 using temp file file:/tmp/checkpoint/commits/.17.00ed855b-d57c-4373-b222-84f68ff58322.tmp
24/09/13 02:44:31 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.17.00ed855b-d57c-4373-b222-84f68ff58322.tmp to file:/tmp/checkpoint/commits/17
24/09/13 02:44:31 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:30.001Z",
  "batchId" : 17,
  "numInputRows" : 9,
  "inputRowsPerSecond" : 1.8,
  "processedRowsPerSecond" : 6.29811056682995,
  "durationMs" : {
    "addBatch" : 1378,
    "commitOffsets" : 11,
    "getBatch" : 0,
    "latestOffset" : 5,
    "queryPlanning" : 7,
    "triggerExecution" : 1429,
    "walCommit" : 24
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 48
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 52
      }
    },
    "latestOffset" : null,
    "numInputRows" : 9,
    "inputRowsPerSecond" : 1.8,
    "processedRowsPerSecond" : 6.29811056682995
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:35 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/18 using temp file file:/tmp/checkpoint/offsets/.18.f3b4d9a4-31bb-4616-8f08-799999fbd6a8.tmp
24/09/13 02:44:35 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.18.f3b4d9a4-31bb-4616-8f08-799999fbd6a8.tmp to file:/tmp/checkpoint/offsets/18
24/09/13 02:44:35 INFO MicroBatchExecution: Committed offsets for batch 18. Metadata OffsetSeqMetadata(0,1726195475005,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:35 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:35,034 - INFO - Received command c on object id p0
24/09/13 02:44:35 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:44:35 INFO DAGScheduler: Got job 51 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:44:35 INFO DAGScheduler: Final stage: ResultStage 51 (isEmpty at <unknown>:0)
24/09/13 02:44:35 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:35 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:35 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[200] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:44:35 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:44:35 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:44:35 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:35 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[200] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:35 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
24/09/13 02:44:35 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 51) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:35 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:35 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 51) in 19 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:35 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
24/09/13 02:44:35 INFO DAGScheduler: ResultStage 51 (isEmpty at <unknown>:0) finished in 0.023 s
24/09/13 02:44:35 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
24/09/13 02:44:35 INFO DAGScheduler: Job 51 finished: isEmpty at <unknown>:0, took 0.025732 s
2024-09-13 02:44:35,070 - INFO - Processing batch 18
2024-09-13 02:44:35,070 - INFO - Batch content:
24/09/13 02:44:35 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 02:44:35 INFO DAGScheduler: Got job 52 (showString at <unknown>:0) with 1 output partitions
24/09/13 02:44:35 INFO DAGScheduler: Final stage: ResultStage 52 (showString at <unknown>:0)
24/09/13 02:44:35 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:35 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:35 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[202] at showString at <unknown>:0), which has no missing parents
24/09/13 02:44:35 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:44:35 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:44:35 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:35 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[202] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:35 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
24/09/13 02:44:35 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 52) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:35 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:35 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 52) in 529 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:35 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
24/09/13 02:44:35 INFO DAGScheduler: ResultStage 52 (showString at <unknown>:0) finished in 0.533 s
24/09/13 02:44:35 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
24/09/13 02:44:35 INFO DAGScheduler: Job 52 finished: showString at <unknown>:0, took 0.534726 s
+----+----------+---------+------+--------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+-------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                       |post_code|email                       |username         |dob                     |registered_date         |phone        |picture                                             |
+----+----------+---------+------+--------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+-------------+----------------------------------------------------+
|NULL|Bernhard  |Nicolas  |male  |5571 Rue de L'Abbaye, Kaiseraugst, Basel-Stadt, Switzerland   |3324     |bernhard.nicolas@example.com|angrymouse213    |1962-04-01T13:40:36.443Z|2006-12-20T22:03:00.004Z|076 283 80 55|https://randomuser.me/api/portraits/med/men/30.jpg  |
|NULL|Urs       |Olivier  |male  |2065 Rue de L'Abb-Gillet, Schattenhalb, Obwalden, Switzerland|7979     |urs.olivier@example.com     |heavybutterfly505|1975-04-17T03:52:35.304Z|2009-08-13T23:01:59.964Z|077 785 59 98|https://randomuser.me/api/portraits/med/men/33.jpg  |
|NULL|Peggy     |Diaz     |female|6644 Paddock Way, Bathurst, Tasmania, Australia               |2533     |peggy.diaz@example.com      |whitepanda107    |1996-07-19T00:22:35.749Z|2021-09-13T01:39:38.673Z|02-8142-1503 |https://randomuser.me/api/portraits/med/women/13.jpg|
+----+----------+---------+------+--------------------------------------------------------------+---------+----------------------------+-----------------+------------------------+------------------------+-------------+----------------------------------------------------+

24/09/13 02:44:35 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:35 INFO DAGScheduler: Got job 53 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:35 INFO DAGScheduler: Final stage: ResultStage 53 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:35 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:35 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:35 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[204] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:35 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 45.7 KiB, free 434.1 MiB)
24/09/13 02:44:35 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.1 MiB)
24/09/13 02:44:35 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:35 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[204] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:35 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
24/09/13 02:44:35 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 53) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:35 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:36 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 53) in 524 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:36 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
24/09/13 02:44:36 INFO DAGScheduler: ResultStage 53 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.528 s
24/09/13 02:44:36 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
24/09/13 02:44:36 INFO DAGScheduler: Job 53 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.529765 s
2024-09-13 02:44:36,168 - INFO - Inserting data: {'id': None, 'first_name': 'Bernhard', 'last_name': 'Nicolas', 'gender': 'male', 'address': "5571 Rue de L'Abbaye, Kaiseraugst, Basel-Stadt, Switzerland", 'post_code': '3324', 'email': 'bernhard.nicolas@example.com', 'username': 'angrymouse213', 'dob': '1962-04-01T13:40:36.443Z', 'registered_date': '2006-12-20T22:03:00.004Z', 'phone': '076 283 80 55', 'picture': 'https://randomuser.me/api/portraits/med/men/30.jpg'}
2024-09-13 02:44:36,171 - INFO - Data inserted for Bernhard Nicolas with ID 8aad31e4-67c4-4bdb-998a-bd999c4526a8
2024-09-13 02:44:36,171 - INFO - Successfully inserted data for Bernhard Nicolas
2024-09-13 02:44:36,171 - INFO - Inserting data: {'id': None, 'first_name': 'Urs', 'last_name': 'Olivier', 'gender': 'male', 'address': "2065 Rue de L'Abb-Gillet, Schattenhalb, Obwalden, Switzerland", 'post_code': '7979', 'email': 'urs.olivier@example.com', 'username': 'heavybutterfly505', 'dob': '1975-04-17T03:52:35.304Z', 'registered_date': '2009-08-13T23:01:59.964Z', 'phone': '077 785 59 98', 'picture': 'https://randomuser.me/api/portraits/med/men/33.jpg'}
2024-09-13 02:44:36,174 - INFO - Data inserted for Urs Olivier with ID d954dd54-9dec-49ac-af3e-66abe8e775e1
2024-09-13 02:44:36,174 - INFO - Successfully inserted data for Urs Olivier
2024-09-13 02:44:36,174 - INFO - Inserting data: {'id': None, 'first_name': 'Peggy', 'last_name': 'Diaz', 'gender': 'female', 'address': '6644 Paddock Way, Bathurst, Tasmania, Australia', 'post_code': '2533', 'email': 'peggy.diaz@example.com', 'username': 'whitepanda107', 'dob': '1996-07-19T00:22:35.749Z', 'registered_date': '2021-09-13T01:39:38.673Z', 'phone': '02-8142-1503', 'picture': 'https://randomuser.me/api/portraits/med/women/13.jpg'}
2024-09-13 02:44:36,177 - INFO - Data inserted for Peggy Diaz with ID b63aa769-e02c-4adc-9f64-2a0d268a2fc5
2024-09-13 02:44:36,178 - INFO - Successfully inserted data for Peggy Diaz
2024-09-13 02:44:36,178 - INFO - Finished processing batch 18
24/09/13 02:44:36 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/18 using temp file file:/tmp/checkpoint/commits/.18.77b1c732-43bb-4c1f-af2c-d9a1b32a149e.tmp
24/09/13 02:44:36 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.18.77b1c732-43bb-4c1f-af2c-d9a1b32a149e.tmp to file:/tmp/checkpoint/commits/18
24/09/13 02:44:36 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:35.002Z",
  "batchId" : 18,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.3997200559888021,
  "processedRowsPerSecond" : 5.867560771165129,
  "durationMs" : {
    "addBatch" : 1153,
    "commitOffsets" : 16,
    "getBatch" : 1,
    "latestOffset" : 3,
    "queryPlanning" : 5,
    "triggerExecution" : 1193,
    "walCommit" : 13
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 52
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 55
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.3997200559888021,
    "processedRowsPerSecond" : 5.867560771165129
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:40 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/19 using temp file file:/tmp/checkpoint/offsets/.19.e56eec3a-3922-4cca-b44a-efd9a05f5487.tmp
24/09/13 02:44:40 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.19.e56eec3a-3922-4cca-b44a-efd9a05f5487.tmp to file:/tmp/checkpoint/offsets/19
24/09/13 02:44:40 INFO MicroBatchExecution: Committed offsets for batch 19. Metadata OffsetSeqMetadata(0,1726195480019,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:40 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:40,059 - INFO - Received command c on object id p0
24/09/13 02:44:40 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:44:40 INFO DAGScheduler: Got job 54 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:44:40 INFO DAGScheduler: Final stage: ResultStage 54 (isEmpty at <unknown>:0)
24/09/13 02:44:40 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:40 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:40 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[211] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:44:40 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 42.8 KiB, free 434.1 MiB)
24/09/13 02:44:40 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.0 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[211] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:40 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
24/09/13 02:44:40 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 54) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:40 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 54) in 541 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:40 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
24/09/13 02:44:40 INFO DAGScheduler: ResultStage 54 (isEmpty at <unknown>:0) finished in 0.544 s
24/09/13 02:44:40 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
24/09/13 02:44:40 INFO DAGScheduler: Job 54 finished: isEmpty at <unknown>:0, took 0.546771 s
2024-09-13 02:44:40,618 - INFO - Processing batch 19
2024-09-13 02:44:40,618 - INFO - Batch content:
24/09/13 02:44:40 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 02:44:40 INFO DAGScheduler: Got job 55 (showString at <unknown>:0) with 1 output partitions
24/09/13 02:44:40 INFO DAGScheduler: Final stage: ResultStage 55 (showString at <unknown>:0)
24/09/13 02:44:40 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:40 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:40 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[213] at showString at <unknown>:0), which has no missing parents
24/09/13 02:44:40 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 46.6 KiB, free 434.0 MiB)
24/09/13 02:44:40 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.0 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[213] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:40 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:40 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:41 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 543 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:41 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
24/09/13 02:44:41 INFO DAGScheduler: ResultStage 55 (showString at <unknown>:0) finished in 0.553 s
24/09/13 02:44:41 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
24/09/13 02:44:41 INFO DAGScheduler: Job 55 finished: showString at <unknown>:0, took 0.554680 s
+----+----------+---------+------+-----------------------------------------------------+---------+--------------------------+--------------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                              |post_code|email                     |username            |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+-----------------------------------------------------+---------+--------------------------+--------------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Raphal   |Renaud   |male  |3345 Rue du Village, Brest, Charente-Maritime, France|64221    |raphael.renaud@example.com|purplebird191       |1956-03-28T02:35:23.851Z|2008-12-06T09:35:07.862Z|03-25-12-84-68|https://randomuser.me/api/portraits/med/men/57.jpg  |
|NULL|Gudrun    |Dupont   |female|1745 Rue Gasparin, Calanca, St. Gallen, Switzerland  |8557     |gudrun.dupont@example.com |whitepeacock161     |1949-04-04T21:30:01.212Z|2020-10-05T04:45:38.990Z|075 873 65 01 |https://randomuser.me/api/portraits/med/women/89.jpg|
|NULL|Donna     |Gray     |female|8235 Rookery Road, Duleek, Kildare, Ireland          |41444    |donna.gray@example.com    |ticklishbutterfly876|1957-12-21T02:53:35.240Z|2006-03-10T16:46:33.897Z|051-413-5407  |https://randomuser.me/api/portraits/med/women/20.jpg|
+----+----------+---------+------+-----------------------------------------------------+---------+--------------------------+--------------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:44:41 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:41 INFO DAGScheduler: Got job 56 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:41 INFO DAGScheduler: Final stage: ResultStage 56 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:41 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:41 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:41 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[215] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:41 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:44:41 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:44:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:41 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[215] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:41 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0
24/09/13 02:44:41 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 56) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:41 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 56) in 540 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:41 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
24/09/13 02:44:41 INFO DAGScheduler: ResultStage 56 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.544 s
24/09/13 02:44:41 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
24/09/13 02:44:41 INFO DAGScheduler: Job 56 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.545527 s
2024-09-13 02:44:41,763 - INFO - Inserting data: {'id': None, 'first_name': 'Raphal', 'last_name': 'Renaud', 'gender': 'male', 'address': '3345 Rue du Village, Brest, Charente-Maritime, France', 'post_code': '64221', 'email': 'raphael.renaud@example.com', 'username': 'purplebird191', 'dob': '1956-03-28T02:35:23.851Z', 'registered_date': '2008-12-06T09:35:07.862Z', 'phone': '03-25-12-84-68', 'picture': 'https://randomuser.me/api/portraits/med/men/57.jpg'}
2024-09-13 02:44:41,766 - INFO - Data inserted for Raphal Renaud with ID 01a3e3cd-6534-4f46-a80e-4a88f13a3f2e
2024-09-13 02:44:41,766 - INFO - Successfully inserted data for Raphal Renaud
2024-09-13 02:44:41,766 - INFO - Inserting data: {'id': None, 'first_name': 'Gudrun', 'last_name': 'Dupont', 'gender': 'female', 'address': '1745 Rue Gasparin, Calanca, St. Gallen, Switzerland', 'post_code': '8557', 'email': 'gudrun.dupont@example.com', 'username': 'whitepeacock161', 'dob': '1949-04-04T21:30:01.212Z', 'registered_date': '2020-10-05T04:45:38.990Z', 'phone': '075 873 65 01', 'picture': 'https://randomuser.me/api/portraits/med/women/89.jpg'}
2024-09-13 02:44:41,770 - INFO - Data inserted for Gudrun Dupont with ID 702fdb72-4b13-4364-a3cb-3103cd7785a9
2024-09-13 02:44:41,770 - INFO - Successfully inserted data for Gudrun Dupont
2024-09-13 02:44:41,770 - INFO - Inserting data: {'id': None, 'first_name': 'Donna', 'last_name': 'Gray', 'gender': 'female', 'address': '8235 Rookery Road, Duleek, Kildare, Ireland', 'post_code': '41444', 'email': 'donna.gray@example.com', 'username': 'ticklishbutterfly876', 'dob': '1957-12-21T02:53:35.240Z', 'registered_date': '2006-03-10T16:46:33.897Z', 'phone': '051-413-5407', 'picture': 'https://randomuser.me/api/portraits/med/women/20.jpg'}
2024-09-13 02:44:41,773 - INFO - Data inserted for Donna Gray with ID 68391a6e-165d-4293-b841-37fe7dd4d472
2024-09-13 02:44:41,773 - INFO - Successfully inserted data for Donna Gray
2024-09-13 02:44:41,773 - INFO - Finished processing batch 19
24/09/13 02:44:41 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/19 using temp file file:/tmp/checkpoint/commits/.19.ea886384-6e71-42c5-a43e-2fbb5324427a.tmp
24/09/13 02:44:41 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.19.ea886384-6e71-42c5-a43e-2fbb5324427a.tmp to file:/tmp/checkpoint/commits/19
24/09/13 02:44:41 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:40.011Z",
  "batchId" : 19,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.3974845278498702,
  "processedRowsPerSecond" : 3.930376193149916,
  "durationMs" : {
    "addBatch" : 1726,
    "commitOffsets" : 18,
    "getBatch" : 0,
    "latestOffset" : 7,
    "queryPlanning" : 7,
    "triggerExecution" : 1781,
    "walCommit" : 19
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 55
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 58
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.3974845278498702,
    "processedRowsPerSecond" : 3.930376193149916
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:45 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/20 using temp file file:/tmp/checkpoint/offsets/.20.5e64c397-d0fa-4220-96c9-09d3cd9671ad.tmp
24/09/13 02:44:45 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.20.5e64c397-d0fa-4220-96c9-09d3cd9671ad.tmp to file:/tmp/checkpoint/offsets/20
24/09/13 02:44:45 INFO MicroBatchExecution: Committed offsets for batch 20. Metadata OffsetSeqMetadata(0,1726195485009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:45 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:45,066 - INFO - Received command c on object id p0
24/09/13 02:44:45 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:44:45 INFO DAGScheduler: Got job 57 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:44:45 INFO DAGScheduler: Final stage: ResultStage 57 (isEmpty at <unknown>:0)
24/09/13 02:44:45 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:45 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:45 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[222] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:44:45 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:44:45 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:44:45 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:45 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[222] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:45 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
24/09/13 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 57) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:45 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:45 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 57) in 12 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
24/09/13 02:44:45 INFO DAGScheduler: ResultStage 57 (isEmpty at <unknown>:0) finished in 0.016 s
24/09/13 02:44:45 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
24/09/13 02:44:45 INFO DAGScheduler: Job 57 finished: isEmpty at <unknown>:0, took 0.016875 s
2024-09-13 02:44:45,094 - INFO - Processing batch 20
2024-09-13 02:44:45,094 - INFO - Batch content:
24/09/13 02:44:45 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 02:44:45 INFO DAGScheduler: Got job 58 (showString at <unknown>:0) with 1 output partitions
24/09/13 02:44:45 INFO DAGScheduler: Final stage: ResultStage 58 (showString at <unknown>:0)
24/09/13 02:44:45 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:45 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:45 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[224] at showString at <unknown>:0), which has no missing parents
24/09/13 02:44:45 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:44:45 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:44:45 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:45 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[224] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:45 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
24/09/13 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 58) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:45 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:45 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 58) in 545 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:45 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
24/09/13 02:44:45 INFO DAGScheduler: ResultStage 58 (showString at <unknown>:0) finished in 0.548 s
24/09/13 02:44:45 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
24/09/13 02:44:45 INFO DAGScheduler: Job 58 finished: showString at <unknown>:0, took 0.550433 s
+----+----------+---------+------+------------------------------------------------------+---------+-----------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                               |post_code|email                        |username     |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+------------------------------------------------------+---------+-----------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Juliete   |Rocha    |female|6151 Rua Tiradentes , Barretos, Esprito Santo, Brazil|37187    |juliete.rocha@example.com    |heavymouse936|1963-02-17T11:53:40.777Z|2006-08-11T09:47:41.946Z|(04) 7549-1104|https://randomuser.me/api/portraits/med/women/2.jpg |
|NULL|Svitogora |G'ereta  |female|1984 Svyatomikolayivska, Rogatin, Poltavska, Ukraine  |60625    |svitogora.g'ereta@example.com|tinytiger673 |1990-09-12T08:06:11.982Z|2016-12-04T17:02:01.768Z|(097) D82-0784|https://randomuser.me/api/portraits/med/women/53.jpg|
|NULL|Allen     |Griffin  |male  |8429 Mcgowen St, Dubbo, South Australia, Australia    |2025     |allen.griffin@example.com    |sadwolf201   |1987-06-13T20:42:06.657Z|2011-10-30T07:37:20.697Z|04-2678-1468  |https://randomuser.me/api/portraits/med/men/36.jpg  |
+----+----------+---------+------+------------------------------------------------------+---------+-----------------------------+-------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:44:45 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:45 INFO DAGScheduler: Got job 59 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:45 INFO DAGScheduler: Final stage: ResultStage 59 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:45 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:45 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:45 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[226] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:45 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 45.7 KiB, free 434.1 MiB)
24/09/13 02:44:45 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.1 MiB)
24/09/13 02:44:45 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:45 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[226] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:45 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0
24/09/13 02:44:45 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 59) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:45 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:46 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 59) in 540 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:46 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
24/09/13 02:44:46 INFO DAGScheduler: ResultStage 59 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.544 s
24/09/13 02:44:46 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
24/09/13 02:44:46 INFO DAGScheduler: Job 59 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.546286 s
2024-09-13 02:44:46,230 - INFO - Inserting data: {'id': None, 'first_name': 'Juliete', 'last_name': 'Rocha', 'gender': 'female', 'address': '6151 Rua Tiradentes , Barretos, Esprito Santo, Brazil', 'post_code': '37187', 'email': 'juliete.rocha@example.com', 'username': 'heavymouse936', 'dob': '1963-02-17T11:53:40.777Z', 'registered_date': '2006-08-11T09:47:41.946Z', 'phone': '(04) 7549-1104', 'picture': 'https://randomuser.me/api/portraits/med/women/2.jpg'}
2024-09-13 02:44:46,235 - INFO - Data inserted for Juliete Rocha with ID 7ee5a9d0-c751-4e13-a36f-545a649cd2ea
2024-09-13 02:44:46,235 - INFO - Successfully inserted data for Juliete Rocha
2024-09-13 02:44:46,236 - INFO - Inserting data: {'id': None, 'first_name': 'Svitogora', 'last_name': "G'ereta", 'gender': 'female', 'address': '1984 Svyatomikolayivska, Rogatin, Poltavska, Ukraine', 'post_code': '60625', 'email': "svitogora.g'ereta@example.com", 'username': 'tinytiger673', 'dob': '1990-09-12T08:06:11.982Z', 'registered_date': '2016-12-04T17:02:01.768Z', 'phone': '(097) D82-0784', 'picture': 'https://randomuser.me/api/portraits/med/women/53.jpg'}
2024-09-13 02:44:46,240 - INFO - Data inserted for Svitogora G'ereta with ID ba887ff8-5cfd-41bb-8192-96c4a238860e
2024-09-13 02:44:46,241 - INFO - Successfully inserted data for Svitogora G'ereta
2024-09-13 02:44:46,241 - INFO - Inserting data: {'id': None, 'first_name': 'Allen', 'last_name': 'Griffin', 'gender': 'male', 'address': '8429 Mcgowen St, Dubbo, South Australia, Australia', 'post_code': '2025', 'email': 'allen.griffin@example.com', 'username': 'sadwolf201', 'dob': '1987-06-13T20:42:06.657Z', 'registered_date': '2011-10-30T07:37:20.697Z', 'phone': '04-2678-1468', 'picture': 'https://randomuser.me/api/portraits/med/men/36.jpg'}
2024-09-13 02:44:46,245 - INFO - Data inserted for Allen Griffin with ID 3b5e0f80-5ea5-4d00-a609-b945b75ccc79
2024-09-13 02:44:46,245 - INFO - Successfully inserted data for Allen Griffin
2024-09-13 02:44:46,246 - INFO - Finished processing batch 20
24/09/13 02:44:46 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/20 using temp file file:/tmp/checkpoint/commits/.20.597e72ab-a5b9-4e8d-8a22-2184d1723c6b.tmp
24/09/13 02:44:46 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.20.597e72ab-a5b9-4e8d-8a22-2184d1723c6b.tmp to file:/tmp/checkpoint/commits/20
24/09/13 02:44:46 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:45.001Z",
  "batchId" : 20,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4028056112224447,
  "processedRowsPerSecond" : 5.511811023622047,
  "durationMs" : {
    "addBatch" : 1192,
    "commitOffsets" : 25,
    "getBatch" : 0,
    "latestOffset" : 7,
    "queryPlanning" : 11,
    "triggerExecution" : 1269,
    "walCommit" : 33
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 58
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 61
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4028056112224447,
    "processedRowsPerSecond" : 5.511811023622047
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:50 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/21 using temp file file:/tmp/checkpoint/offsets/.21.5642996f-29dd-496c-8d82-ca49a5572e29.tmp
24/09/13 02:44:50 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.21.5642996f-29dd-496c-8d82-ca49a5572e29.tmp to file:/tmp/checkpoint/offsets/21
24/09/13 02:44:50 INFO MicroBatchExecution: Committed offsets for batch 21. Metadata OffsetSeqMetadata(0,1726195490021,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:50 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:50,063 - INFO - Received command c on object id p0
24/09/13 02:44:50 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:44:50 INFO DAGScheduler: Got job 60 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:44:50 INFO DAGScheduler: Final stage: ResultStage 60 (isEmpty at <unknown>:0)
24/09/13 02:44:50 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:50 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:50 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[233] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:44:50 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 42.8 KiB, free 434.1 MiB)
24/09/13 02:44:50 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.0 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:50 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[233] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:50 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
24/09/13 02:44:50 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 60) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 60) in 20 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:50 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
24/09/13 02:44:50 INFO DAGScheduler: ResultStage 60 (isEmpty at <unknown>:0) finished in 0.029 s
24/09/13 02:44:50 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
24/09/13 02:44:50 INFO DAGScheduler: Job 60 finished: isEmpty at <unknown>:0, took 0.030557 s
2024-09-13 02:44:50,106 - INFO - Processing batch 21
2024-09-13 02:44:50,106 - INFO - Batch content:
24/09/13 02:44:50 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 02:44:50 INFO DAGScheduler: Got job 61 (showString at <unknown>:0) with 1 output partitions
24/09/13 02:44:50 INFO DAGScheduler: Final stage: ResultStage 61 (showString at <unknown>:0)
24/09/13 02:44:50 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:50 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:50 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[235] at showString at <unknown>:0), which has no missing parents
24/09/13 02:44:50 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 46.6 KiB, free 434.3 MiB)
24/09/13 02:44:50 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.3 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[235] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:50 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
24/09/13 02:44:50 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 61) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:50 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 61) in 534 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:50 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
24/09/13 02:44:50 INFO DAGScheduler: ResultStage 61 (showString at <unknown>:0) finished in 0.538 s
24/09/13 02:44:50 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
24/09/13 02:44:50 INFO DAGScheduler: Job 61 finished: showString at <unknown>:0, took 0.539536 s
+----+----------+---------+------+--------------------------------------------------------------+---------+--------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                                       |post_code|email                     |username         |dob                     |registered_date         |phone         |picture                                             |
+----+----------+---------+------+--------------------------------------------------------------+---------+--------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Lori      |Clark    |female|4272 Fincher Rd, Oceanside, North Dakota, United States       |23771    |lori.clark@example.com    |organicpeacock773|1971-05-22T01:45:24.186Z|2009-04-01T04:53:36.292Z|(339) 495-7182|https://randomuser.me/api/portraits/med/women/40.jpg|
|NULL|Martn    |Jimnez  |male  |189 Calle de La Democracia, Barcelona, Regin de Murcia, Spain|67848    |martin.jimenez@example.com|ticklishfish873  |1961-11-17T02:26:03.823Z|2010-01-19T20:13:16.223Z|972-896-328   |https://randomuser.me/api/portraits/med/men/62.jpg  |
|NULL|Emily     |Freeman  |female|7410 Park Lane, St Albans, Merseyside, United Kingdom         |L73 9TB  |emily.freeman@example.com |goldenpanda364   |1948-12-12T21:19:33.868Z|2004-01-31T01:57:05.396Z|016977 28141  |https://randomuser.me/api/portraits/med/women/55.jpg|
|NULL|Jennifer  |Owens    |female|818 Church Lane, Cavan, Louth, Ireland                        |96926    |jennifer.owens@example.com|angrymeercat574  |1970-04-28T18:34:45.102Z|2009-06-04T10:36:18.311Z|021-295-4905  |https://randomuser.me/api/portraits/med/women/43.jpg|
+----+----------+---------+------+--------------------------------------------------------------+---------+--------------------------+-----------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:44:50 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:50 INFO DAGScheduler: Got job 62 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:50 INFO DAGScheduler: Final stage: ResultStage 62 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:50 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:50 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:50 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[237] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:50 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 45.7 KiB, free 434.2 MiB)
24/09/13 02:44:50 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
24/09/13 02:44:50 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[237] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:50 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
24/09/13 02:44:50 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 62) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:50 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:50 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 62) in 277 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:50 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
24/09/13 02:44:50 INFO DAGScheduler: ResultStage 62 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.283 s
24/09/13 02:44:50 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished
24/09/13 02:44:50 INFO DAGScheduler: Job 62 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.285536 s
2024-09-13 02:44:50,973 - INFO - Inserting data: {'id': None, 'first_name': 'Lori', 'last_name': 'Clark', 'gender': 'female', 'address': '4272 Fincher Rd, Oceanside, North Dakota, United States', 'post_code': '23771', 'email': 'lori.clark@example.com', 'username': 'organicpeacock773', 'dob': '1971-05-22T01:45:24.186Z', 'registered_date': '2009-04-01T04:53:36.292Z', 'phone': '(339) 495-7182', 'picture': 'https://randomuser.me/api/portraits/med/women/40.jpg'}
2024-09-13 02:44:50,976 - INFO - Data inserted for Lori Clark with ID 4f2ab563-854d-472c-97bb-7c5714f549d1
2024-09-13 02:44:50,976 - INFO - Successfully inserted data for Lori Clark
2024-09-13 02:44:50,977 - INFO - Inserting data: {'id': None, 'first_name': 'Martn', 'last_name': 'Jimnez', 'gender': 'male', 'address': '189 Calle de La Democracia, Barcelona, Regin de Murcia, Spain', 'post_code': '67848', 'email': 'martin.jimenez@example.com', 'username': 'ticklishfish873', 'dob': '1961-11-17T02:26:03.823Z', 'registered_date': '2010-01-19T20:13:16.223Z', 'phone': '972-896-328', 'picture': 'https://randomuser.me/api/portraits/med/men/62.jpg'}
2024-09-13 02:44:50,981 - INFO - Data inserted for Martn Jimnez with ID 51d1edec-4a5b-4969-9aae-b191822ccef5
2024-09-13 02:44:50,981 - INFO - Successfully inserted data for Martn Jimnez
2024-09-13 02:44:50,981 - INFO - Inserting data: {'id': None, 'first_name': 'Emily', 'last_name': 'Freeman', 'gender': 'female', 'address': '7410 Park Lane, St Albans, Merseyside, United Kingdom', 'post_code': 'L73 9TB', 'email': 'emily.freeman@example.com', 'username': 'goldenpanda364', 'dob': '1948-12-12T21:19:33.868Z', 'registered_date': '2004-01-31T01:57:05.396Z', 'phone': '016977 28141', 'picture': 'https://randomuser.me/api/portraits/med/women/55.jpg'}
2024-09-13 02:44:50,984 - INFO - Data inserted for Emily Freeman with ID 9190c7a6-9fd9-4292-80d5-46005a92605a
2024-09-13 02:44:50,984 - INFO - Successfully inserted data for Emily Freeman
2024-09-13 02:44:50,984 - INFO - Inserting data: {'id': None, 'first_name': 'Jennifer', 'last_name': 'Owens', 'gender': 'female', 'address': '818 Church Lane, Cavan, Louth, Ireland', 'post_code': '96926', 'email': 'jennifer.owens@example.com', 'username': 'angrymeercat574', 'dob': '1970-04-28T18:34:45.102Z', 'registered_date': '2009-06-04T10:36:18.311Z', 'phone': '021-295-4905', 'picture': 'https://randomuser.me/api/portraits/med/women/43.jpg'}
2024-09-13 02:44:50,987 - INFO - Data inserted for Jennifer Owens with ID 0310c623-8522-4550-bf7e-e231525cbe95
2024-09-13 02:44:50,987 - INFO - Successfully inserted data for Jennifer Owens
2024-09-13 02:44:50,987 - INFO - Finished processing batch 21
24/09/13 02:44:50 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/21 using temp file file:/tmp/checkpoint/commits/.21.536eb1e1-1db4-49f7-9e31-5100f6b7bff4.tmp
24/09/13 02:44:51 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.21.536eb1e1-1db4-49f7-9e31-5100f6b7bff4.tmp to file:/tmp/checkpoint/commits/21
24/09/13 02:44:51 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:50.002Z",
  "batchId" : 21,
  "numInputRows" : 9,
  "inputRowsPerSecond" : 1.7996400719856027,
  "processedRowsPerSecond" : 8.991008991008991,
  "durationMs" : {
    "addBatch" : 937,
    "commitOffsets" : 16,
    "getBatch" : 0,
    "latestOffset" : 18,
    "queryPlanning" : 8,
    "triggerExecution" : 1000,
    "walCommit" : 20
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 61
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 65
      }
    },
    "latestOffset" : null,
    "numInputRows" : 9,
    "inputRowsPerSecond" : 1.7996400719856027,
    "processedRowsPerSecond" : 8.991008991008991
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:44:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/22 using temp file file:/tmp/checkpoint/offsets/.22.97f3cc44-3f8c-4fd2-81b1-ed309d0dd94d.tmp
24/09/13 02:44:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.22.97f3cc44-3f8c-4fd2-81b1-ed309d0dd94d.tmp to file:/tmp/checkpoint/offsets/22
24/09/13 02:44:55 INFO MicroBatchExecution: Committed offsets for batch 22. Metadata OffsetSeqMetadata(0,1726195495006,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:44:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:44:55 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:44:55,037 - INFO - Received command c on object id p0
24/09/13 02:44:55 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:44:55 INFO DAGScheduler: Got job 63 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:44:55 INFO DAGScheduler: Final stage: ResultStage 63 (isEmpty at <unknown>:0)
24/09/13 02:44:55 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:55 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:55 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[244] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:44:55 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:44:55 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:55 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[244] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:55 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
24/09/13 02:44:55 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 63) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:55 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.3 MiB)
24/09/13 02:44:55 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 63) in 17 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:55 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
24/09/13 02:44:55 INFO DAGScheduler: ResultStage 63 (isEmpty at <unknown>:0) finished in 0.021 s
24/09/13 02:44:55 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
24/09/13 02:44:55 INFO DAGScheduler: Job 63 finished: isEmpty at <unknown>:0, took 0.022262 s
2024-09-13 02:44:55,068 - INFO - Processing batch 22
2024-09-13 02:44:55,069 - INFO - Batch content:
24/09/13 02:44:55 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 02:44:55 INFO DAGScheduler: Got job 64 (showString at <unknown>:0) with 1 output partitions
24/09/13 02:44:55 INFO DAGScheduler: Final stage: ResultStage 64 (showString at <unknown>:0)
24/09/13 02:44:55 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:55 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:55 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[246] at showString at <unknown>:0), which has no missing parents
24/09/13 02:44:55 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 46.6 KiB, free 434.1 MiB)
24/09/13 02:44:55 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.1 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:44:55 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[246] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:55 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:44:55 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 64) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 64) in 227 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:55 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
24/09/13 02:44:55 INFO DAGScheduler: ResultStage 64 (showString at <unknown>:0) finished in 0.234 s
24/09/13 02:44:55 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
24/09/13 02:44:55 INFO DAGScheduler: Job 64 finished: showString at <unknown>:0, took 0.235148 s
+----+----------+----------+------+-----------------------------------------------------------------+---------+------------------------------+------------------+------------------------+------------------------+--------------+----------------------------------------------------+
|id  |first_name|last_name |gender|address                                                          |post_code|email                         |username          |dob                     |registered_date         |phone         |picture                                             |
+----+----------+----------+------+-----------------------------------------------------------------+---------+------------------------------+------------------+------------------------+------------------------+--------------+----------------------------------------------------+
|NULL|Nika      |Savoyka   |female|816 Vasilya Donchuka, Teplodar, Rivnenska, Ukraine               |80812    |nika.savoyka@example.com      |biggoose846       |1986-10-29T12:19:28.381Z|2009-11-04T23:18:46.072Z|(096) J60-2207|https://randomuser.me/api/portraits/med/women/63.jpg|
|NULL|Stine     |Anfinsen  |female|5089 Trygve Strmbergs vei, Svelvik, Finnmark - Finnmrku, Norway|0681     |stine.anfinsen@example.com    |crazyladybug441   |1984-08-24T10:48:51.505Z|2003-09-20T11:26:14.137Z|85424114      |https://randomuser.me/api/portraits/med/women/8.jpg |
|NULL|Deborah   |Cunningham|female|2332 The Drive, Lincoln, Central, United Kingdom                 |B7 6AD   |deborah.cunningham@example.com|organicelephant337|1983-03-25T12:51:00.565Z|2010-06-13T08:16:10.446Z|01728 048202  |https://randomuser.me/api/portraits/med/women/30.jpg|
+----+----------+----------+------+-----------------------------------------------------------------+---------+------------------------------+------------------+------------------------+------------------------+--------------+----------------------------------------------------+

24/09/13 02:44:55 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:44:55 INFO DAGScheduler: Got job 65 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:44:55 INFO DAGScheduler: Final stage: ResultStage 65 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:44:55 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:44:55 INFO DAGScheduler: Missing parents: List()
24/09/13 02:44:55 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[248] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:44:55 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 45.7 KiB, free 434.3 MiB)
24/09/13 02:44:55 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
24/09/13 02:44:55 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1585
24/09/13 02:44:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[248] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:44:55 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0
24/09/13 02:44:55 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 65) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:44:55 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:44:55 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 65) in 541 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:44:55 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
24/09/13 02:44:55 INFO DAGScheduler: ResultStage 65 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.544 s
24/09/13 02:44:55 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:44:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
24/09/13 02:44:55 INFO DAGScheduler: Job 65 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.546057 s
2024-09-13 02:44:55,882 - INFO - Inserting data: {'id': None, 'first_name': 'Nika', 'last_name': 'Savoyka', 'gender': 'female', 'address': '816 Vasilya Donchuka, Teplodar, Rivnenska, Ukraine', 'post_code': '80812', 'email': 'nika.savoyka@example.com', 'username': 'biggoose846', 'dob': '1986-10-29T12:19:28.381Z', 'registered_date': '2009-11-04T23:18:46.072Z', 'phone': '(096) J60-2207', 'picture': 'https://randomuser.me/api/portraits/med/women/63.jpg'}
2024-09-13 02:44:55,886 - INFO - Data inserted for Nika Savoyka with ID 3dc5bdcd-3c53-49b3-a3e9-edf7219c9181
2024-09-13 02:44:55,886 - INFO - Successfully inserted data for Nika Savoyka
2024-09-13 02:44:55,886 - INFO - Inserting data: {'id': None, 'first_name': 'Stine', 'last_name': 'Anfinsen', 'gender': 'female', 'address': '5089 Trygve Strmbergs vei, Svelvik, Finnmark - Finnmrku, Norway', 'post_code': '0681', 'email': 'stine.anfinsen@example.com', 'username': 'crazyladybug441', 'dob': '1984-08-24T10:48:51.505Z', 'registered_date': '2003-09-20T11:26:14.137Z', 'phone': '85424114', 'picture': 'https://randomuser.me/api/portraits/med/women/8.jpg'}
2024-09-13 02:44:55,890 - INFO - Data inserted for Stine Anfinsen with ID 328e4b60-514e-450d-9439-1b4e7cf5b671
2024-09-13 02:44:55,890 - INFO - Successfully inserted data for Stine Anfinsen
2024-09-13 02:44:55,890 - INFO - Inserting data: {'id': None, 'first_name': 'Deborah', 'last_name': 'Cunningham', 'gender': 'female', 'address': '2332 The Drive, Lincoln, Central, United Kingdom', 'post_code': 'B7 6AD', 'email': 'deborah.cunningham@example.com', 'username': 'organicelephant337', 'dob': '1983-03-25T12:51:00.565Z', 'registered_date': '2010-06-13T08:16:10.446Z', 'phone': '01728 048202', 'picture': 'https://randomuser.me/api/portraits/med/women/30.jpg'}
2024-09-13 02:44:55,894 - INFO - Data inserted for Deborah Cunningham with ID f8ad43b8-3070-4df5-a299-a09d473c5e17
2024-09-13 02:44:55,894 - INFO - Successfully inserted data for Deborah Cunningham
2024-09-13 02:44:55,894 - INFO - Finished processing batch 22
24/09/13 02:44:55 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/22 using temp file file:/tmp/checkpoint/commits/.22.476b6856-dcde-4060-bf33-02b4fcae78cb.tmp
24/09/13 02:44:55 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.22.476b6856-dcde-4060-bf33-02b4fcae78cb.tmp to file:/tmp/checkpoint/commits/22
24/09/13 02:44:55 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:44:55.001Z",
  "batchId" : 22,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4002800560112023,
  "processedRowsPerSecond" : 7.667031763417305,
  "durationMs" : {
    "addBatch" : 866,
    "commitOffsets" : 20,
    "getBatch" : 0,
    "latestOffset" : 4,
    "queryPlanning" : 5,
    "triggerExecution" : 913,
    "walCommit" : 16
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 65
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 68
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4002800560112023,
    "processedRowsPerSecond" : 7.667031763417305
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:45:00 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/23 using temp file file:/tmp/checkpoint/offsets/.23.de4eb3f6-9c09-457d-b46e-4e249f40c6cc.tmp
24/09/13 02:45:00 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.23.de4eb3f6-9c09-457d-b46e-4e249f40c6cc.tmp to file:/tmp/checkpoint/offsets/23
24/09/13 02:45:00 INFO MicroBatchExecution: Committed offsets for batch 23. Metadata OffsetSeqMetadata(0,1726195500008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:45:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:45:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:45:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:45:00 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:45:00,046 - INFO - Received command c on object id p0
24/09/13 02:45:00 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:45:00 INFO DAGScheduler: Got job 66 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:45:00 INFO DAGScheduler: Final stage: ResultStage 66 (isEmpty at <unknown>:0)
24/09/13 02:45:00 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:45:00 INFO DAGScheduler: Missing parents: List()
24/09/13 02:45:00 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[255] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:45:00 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 42.8 KiB, free 434.2 MiB)
24/09/13 02:45:00 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.2 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1585
24/09/13 02:45:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[255] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:45:00 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
24/09/13 02:45:00 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 66) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:45:00 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 66) in 21 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:45:00 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
24/09/13 02:45:00 INFO DAGScheduler: ResultStage 66 (isEmpty at <unknown>:0) finished in 0.024 s
24/09/13 02:45:00 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:45:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
24/09/13 02:45:00 INFO DAGScheduler: Job 66 finished: isEmpty at <unknown>:0, took 0.025202 s
2024-09-13 02:45:00,082 - INFO - Processing batch 23
2024-09-13 02:45:00,082 - INFO - Batch content:
24/09/13 02:45:00 INFO SparkContext: Starting job: showString at <unknown>:0
24/09/13 02:45:00 INFO DAGScheduler: Got job 67 (showString at <unknown>:0) with 1 output partitions
24/09/13 02:45:00 INFO DAGScheduler: Final stage: ResultStage 67 (showString at <unknown>:0)
24/09/13 02:45:00 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:45:00 INFO DAGScheduler: Missing parents: List()
24/09/13 02:45:00 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[257] at showString at <unknown>:0), which has no missing parents
24/09/13 02:45:00 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 46.6 KiB, free 434.2 MiB)
24/09/13 02:45:00 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 434.2 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 325496eabbd9:34679 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:45:00 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1585
24/09/13 02:45:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[257] at showString at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:45:00 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
24/09/13 02:45:00 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 67) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:45:00 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 172.24.0.8:42021 (size: 16.5 KiB, free: 434.3 MiB)
24/09/13 02:45:00 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 67) in 530 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:45:00 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
24/09/13 02:45:00 INFO DAGScheduler: ResultStage 67 (showString at <unknown>:0) finished in 0.533 s
24/09/13 02:45:00 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:45:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
24/09/13 02:45:00 INFO DAGScheduler: Job 67 finished: showString at <unknown>:0, took 0.534387 s
+----+----------+---------+------+--------------------------------------------------+---------+---------------------------+--------------+------------------------+------------------------+-------------+----------------------------------------------------+
|id  |first_name|last_name|gender|address                                           |post_code|email                      |username      |dob                     |registered_date         |phone        |picture                                             |
+----+----------+---------+------+--------------------------------------------------+---------+---------------------------+--------------+------------------------+------------------------+-------------+----------------------------------------------------+
|NULL|Harmpje   |Kremers  |female|9004 Bogaardlaan, Saasveld, Groningen, Netherlands|7206 ZT  |harmpje.kremers@example.com|goldenzebra337|1976-05-18T08:21:17.482Z|2021-06-12T15:36:22.176Z|(044) 6823218|https://randomuser.me/api/portraits/med/women/49.jpg|
|NULL|Zachary   |Barnaby  |male  |7300 Tecumseh Rd, Shelbourne, Qubec, Canada      |I2A 9W4  |zachary.barnaby@example.com|whitetiger791 |1970-09-24T19:47:04.670Z|2019-11-20T00:31:02.238Z|Q31 F94-9092 |https://randomuser.me/api/portraits/med/men/56.jpg  |
|NULL|Rebekka   |Buerle  |female|9747 Fliederweg, Rothenburg/O.L., Sachsen, Germany|95837    |rebekka.bauerle@example.com|purplegoose111|1950-10-31T05:39:36.925Z|2008-12-13T11:39:06.020Z|0727-6257915 |https://randomuser.me/api/portraits/med/women/67.jpg|
+----+----------+---------+------+--------------------------------------------------+---------+---------------------------+--------------+------------------------+------------------------+-------------+----------------------------------------------------+

24/09/13 02:45:00 INFO SparkContext: Starting job: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
24/09/13 02:45:00 INFO DAGScheduler: Got job 68 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
24/09/13 02:45:00 INFO DAGScheduler: Final stage: ResultStage 68 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
24/09/13 02:45:00 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:45:00 INFO DAGScheduler: Missing parents: List()
24/09/13 02:45:00 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[259] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
24/09/13 02:45:00 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 45.7 KiB, free 434.1 MiB)
24/09/13 02:45:00 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.1 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 325496eabbd9:34679 (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 325496eabbd9:34679 in memory (size: 16.3 KiB, free: 434.3 MiB)
24/09/13 02:45:00 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1585
24/09/13 02:45:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[259] at call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
24/09/13 02:45:00 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 172.24.0.8:42021 in memory (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 68) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 172.24.0.8:42021 (size: 16.3 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 325496eabbd9:34679 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 172.24.0.8:42021 in memory (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 325496eabbd9:34679 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:45:00 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 172.24.0.8:42021 in memory (size: 16.5 KiB, free: 434.4 MiB)
24/09/13 02:45:01 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 68) in 536 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:45:01 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
24/09/13 02:45:01 INFO DAGScheduler: ResultStage 68 (call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.547 s
24/09/13 02:45:01 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:45:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished
24/09/13 02:45:01 INFO DAGScheduler: Job 68 finished: call at /opt/bitnami/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.549169 s
2024-09-13 02:45:01,204 - INFO - Inserting data: {'id': None, 'first_name': 'Harmpje', 'last_name': 'Kremers', 'gender': 'female', 'address': '9004 Bogaardlaan, Saasveld, Groningen, Netherlands', 'post_code': '7206 ZT', 'email': 'harmpje.kremers@example.com', 'username': 'goldenzebra337', 'dob': '1976-05-18T08:21:17.482Z', 'registered_date': '2021-06-12T15:36:22.176Z', 'phone': '(044) 6823218', 'picture': 'https://randomuser.me/api/portraits/med/women/49.jpg'}
2024-09-13 02:45:01,209 - INFO - Data inserted for Harmpje Kremers with ID feadb004-fde5-4b2b-bf76-c848acaaa15e
2024-09-13 02:45:01,209 - INFO - Successfully inserted data for Harmpje Kremers
2024-09-13 02:45:01,209 - INFO - Inserting data: {'id': None, 'first_name': 'Zachary', 'last_name': 'Barnaby', 'gender': 'male', 'address': '7300 Tecumseh Rd, Shelbourne, Qubec, Canada', 'post_code': 'I2A 9W4', 'email': 'zachary.barnaby@example.com', 'username': 'whitetiger791', 'dob': '1970-09-24T19:47:04.670Z', 'registered_date': '2019-11-20T00:31:02.238Z', 'phone': 'Q31 F94-9092', 'picture': 'https://randomuser.me/api/portraits/med/men/56.jpg'}
2024-09-13 02:45:01,214 - INFO - Data inserted for Zachary Barnaby with ID b970ef70-f59e-45f2-85dd-83d55724f3d4
2024-09-13 02:45:01,214 - INFO - Successfully inserted data for Zachary Barnaby
2024-09-13 02:45:01,214 - INFO - Inserting data: {'id': None, 'first_name': 'Rebekka', 'last_name': 'Buerle', 'gender': 'female', 'address': '9747 Fliederweg, Rothenburg/O.L., Sachsen, Germany', 'post_code': '95837', 'email': 'rebekka.bauerle@example.com', 'username': 'purplegoose111', 'dob': '1950-10-31T05:39:36.925Z', 'registered_date': '2008-12-13T11:39:06.020Z', 'phone': '0727-6257915', 'picture': 'https://randomuser.me/api/portraits/med/women/67.jpg'}
2024-09-13 02:45:01,217 - INFO - Data inserted for Rebekka Buerle with ID 96235b5a-9183-4c5b-be45-5a379839e970
2024-09-13 02:45:01,217 - INFO - Successfully inserted data for Rebekka Buerle
2024-09-13 02:45:01,217 - INFO - Finished processing batch 23
24/09/13 02:45:01 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/commits/23 using temp file file:/tmp/checkpoint/commits/.23.58570fe3-5120-4cdd-82c9-ad0dc1cb0da3.tmp
24/09/13 02:45:01 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/commits/.23.58570fe3-5120-4cdd-82c9-ad0dc1cb0da3.tmp to file:/tmp/checkpoint/commits/23
24/09/13 02:45:01 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "b7ac8922-8d26-430a-83ec-671d095ee3df",
  "runId" : "ccd92a03-eae0-4b90-aa3f-dcd3fe00bfb4",
  "name" : null,
  "timestamp" : "2024-09-13T02:45:00.001Z",
  "batchId" : 23,
  "numInputRows" : 7,
  "inputRowsPerSecond" : 1.4,
  "processedRowsPerSecond" : 5.645161290322581,
  "durationMs" : {
    "addBatch" : 1183,
    "commitOffsets" : 23,
    "getBatch" : 0,
    "latestOffset" : 7,
    "queryPlanning" : 7,
    "triggerExecution" : 1240,
    "walCommit" : 18
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[user_data]]",
    "startOffset" : {
      "user_data" : {
        "0" : 68
      }
    },
    "endOffset" : {
      "user_data" : {
        "0" : 71
      }
    },
    "latestOffset" : null,
    "numInputRows" : 7,
    "inputRowsPerSecond" : 1.4,
    "processedRowsPerSecond" : 5.645161290322581
  } ],
  "sink" : {
    "description" : "ForeachBatchSink",
    "numOutputRows" : -1
  }
}
24/09/13 02:45:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/checkpoint/offsets/24 using temp file file:/tmp/checkpoint/offsets/.24.ad0b8359-d92b-4638-9d00-e548765e9f42.tmp
24/09/13 02:45:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/checkpoint/offsets/.24.ad0b8359-d92b-4638-9d00-e548765e9f42.tmp to file:/tmp/checkpoint/offsets/24
24/09/13 02:45:05 INFO MicroBatchExecution: Committed offsets for batch 24. Metadata OffsetSeqMetadata(0,1726195505020,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
24/09/13 02:45:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:45:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:45:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
24/09/13 02:45:05 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
2024-09-13 02:45:05,069 - INFO - Received command c on object id p0
24/09/13 02:45:05 INFO SparkContext: Starting job: isEmpty at <unknown>:0
24/09/13 02:45:05 INFO DAGScheduler: Got job 69 (isEmpty at <unknown>:0) with 1 output partitions
24/09/13 02:45:05 INFO DAGScheduler: Final stage: ResultStage 69 (isEmpty at <unknown>:0)
24/09/13 02:45:05 INFO DAGScheduler: Parents of final stage: List()
24/09/13 02:45:05 INFO DAGScheduler: Missing parents: List()
24/09/13 02:45:05 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[266] at isEmpty at <unknown>:0), which has no missing parents
24/09/13 02:45:05 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 42.8 KiB, free 434.3 MiB)
24/09/13 02:45:05 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 434.3 MiB)
24/09/13 02:45:05 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 325496eabbd9:34679 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:45:05 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1585
24/09/13 02:45:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[266] at isEmpty at <unknown>:0) (first 15 tasks are for partitions Vector(0))
24/09/13 02:45:05 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
24/09/13 02:45:05 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 69) (172.24.0.8, executor 0, partition 0, PROCESS_LOCAL, 15039 bytes) 
24/09/13 02:45:05 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 172.24.0.8:42021 (size: 15.7 KiB, free: 434.4 MiB)
24/09/13 02:45:05 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 69) in 13 ms on 172.24.0.8 (executor 0) (1/1)
24/09/13 02:45:05 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
24/09/13 02:45:05 INFO DAGScheduler: ResultStage 69 (isEmpty at <unknown>:0) finished in 0.016 s
24/09/13 02:45:05 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/13 02:45:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
24/09/13 02:45:05 INFO DAGScheduler: Job 69 finished: isEmpty at <unknown>:0, took 0.018564 s
2024-09-13 02:45:05,099 - INFO - Processing batch 24
2024-09-13 02:45:05,100 - INFO - Batch content:
